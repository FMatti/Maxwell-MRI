\documentclass[11pt, a4paper]{article}

\usepackage{style}

\institution{EPFL}
\project{Semester Project}
\title{Minimal Rational Interpolation for Time-Harmonic Maxwell's Equations}
\author{Fabio Matti}
\supervisor{Prof. Fabio Nobile \\ Dr. Davide Pradovera}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
    \acrfull{MRI} provides an efficient and reliable way to approximate the 
    dependence of a characteristic quantity of a model on one of its parameters.
    The focus of this report is put on the \acrfull{gMRI} algorithm and particularly
    on way to enhance its performance. This algorithm is then applied to three 
    example problems concerning the time-harmonic Maxwell's equations in the 
    frequency domain. A brief evaluation of the advantages and disadvantages of
    \acrshort{gMRI} as compared to conventional approaches for finding quantities,
    such as resonant modes, of interest for problems of this type is conducted.
\end{abstract}

\newpage
\printglossary[type=\acronymtype, nonumberlist]

\newpage
\tableofcontents

\newpage
\section{Introduction}
\label{sec:introduction}

A wide class of problems in physics and engineering concerns itself with the
study of the dependence of a model on one of its parameters. 
Of interest is usually a characteristic quantity that covaries with said parameter.
Unless the system allows for an analytical solution, one may usually only
find numerical solutions to the system for discrete values of the parameter.
\acrfull{MRI} offers a way to locally approximate the continuous
dependence of a model on one of its parameters. The approach has proven
effective and efficient (both memory- and computation wise) in applications
on Helmholtz-type problems \cite{greedyMRI, shortMRI}.

Central to this report are time-harmonic electromagnetic problems, whose 
parameter is the (angular) frequency. These problems are governed by
the time-harmonic Maxwell's equations. Choosing the quantity of interest
to be a vector potential, these equations reduce to a single curl-curl equation.
A justification for why a rational interpolation approach is appropriate for
this class of problems will be presented in Section \ref{subsec:motivation}.

The first few pages in this report are a short guide for finding numerical 
solutions to the time-harmonic Maxwell's equations using the \acrfull{FEM}.
These solutions are then used in the core of this report, which gives a description
of the \acrfull{gMRI} algorithm. Properties of and optimization tricks for the
\acrshort{gMRI} are shown. In the end, three applications of the method are studied and
discussed: the resonant modes of a two-dimensional resonant cavity,
the two-dimensional cavity with an imperfectly conducting boundary, and lastly
the scattering coefficients of a \acrfull{DMCWF}.

\newpage
\section{Finite element discretization of the time-harmonic Maxwell's equations}
\label{sec:maxwell}

\acrfull{MRI} requires the knowledge of the solution of the problem for multiple 
values of the model parameter that is of interested. A way of obtaining these
solutions is the \acrfull{FEM}. For that purpose, I now derive a strong formulation
for the time-harmonic Maxwell problem and subsequently convert it to its
corresponding weak formulation.

\subsection{Vector potential formulation of the time-harmonic Maxwell's equations}
\label{subsec:maxwell-potential}
% !REMINDME: Add boundary conditions to th equations!!!!

% Everything smooth enough to do all manipulations...
I assume that all quantities in this section are smooth enough to perform the
necessary vector calculus manipulations.

Let $\mathbf{E}$ denote an electric field, $\mathbf{B}$ a magnetic field
strength, $\rho$ an electric charge density, and $\mathbf{j}$ an electric
current density. Maxwell's equations are stated in \citep{monk} as
\begin{align}
    \nabla \cdot (\epsilon \mathbf{E}) &= \rho \label{equ:maxwell1} \\
    \nabla \cdot \mathbf{B} &= 0 \label{equ:maxwell2} \\
    \nabla \times \mathbf{E} &= -\partial_t \mathbf{B} \label{equ:maxwell3} \\
    \nabla \times (\mu^{-1} \mathbf{B}) &= \partial_t (\epsilon \mathbf{E}) + \mathbf{j} \label{equ:maxwell4}
\end{align}
with $\varepsilon$ being the permittivity and $\mu$ the permeability (whose names 
let alone their values I always tend to forget).

% Non-conducting material, else => j = sigma*E + J_a (Monk 21)

Equation (\ref{equ:maxwell2}) motivates the expression of the magnetic field 
$\mathbf{B} = \nabla \times \mathbf{u}$ in terms of a vector valued function
$\mathbf{u}$, the vector potential (in literature commonly denoted with
$\mathbf{A}$). Similarly, (\ref{equ:maxwell3}) suggests
rewriting the electric field $\mathbf{E} = - \nabla \phi - \partial_t \mathbf{u}$
using a scalar function $\phi$, referred to as the scalar potential.

The physical quantities $\mathbf{E}$ and $\mathbf{B}$ remain unchanged 
if we transform $\mathbf{u} \to \mathbf{u}' = \mathbf{u} + \nabla \psi$ or
$\phi \to \phi' = \phi - \partial_t \psi$ for arbitrary functions $\psi$.
A convenient choice of $\psi$ is suggested in \citep{gauge-transformation} to be
\begin{equation}
    \psi = \int_0^t \phi dt' \label{equ:gauge}
\end{equation}
which transforms $\phi \to \phi' = 0$ and $\mathbf{u} \to \mathbf{u}' = \mathbf{u}
+ \nabla \int_0^t \phi dt'$. Thus, the expressions for the electrical and
magnetic field become
\begin{align}
    \mathbf{E} &= -\partial_t \mathbf{u} \label{equ:electricfield} \\
    \mathbf{B} &= \nabla \times \mathbf{u} \label{equ:magneticfield}
\end{align}
where I have subtly renamed the variable $\mathbf{u}'$ to $\mathbf{u}$ for simplicity.

Plugging the identities (\ref{equ:electricfield}) and (\ref{equ:magneticfield})
into (\ref{equ:maxwell4}) yields 
\begin{equation}
    \nabla \times (\mu^{-1} \nabla \times \mathbf{u}) = - \epsilon \partial_t^2 \mathbf{u} + \mathbf{j} \label{equ:maxwell-potential}
\end{equation}

For the rest of this report, I restrict myself to vector potentials $\mathbf{u}$
that exhibit a harmonic dependence on time $t$, i.e. may be factorized into
a term solely depending on the position $\mathbf{x}$ and a complex exponential
depending on time
\begin{equation}
    \mathbf{u}(\mathbf{x}, t) = \mathbf{u}(\mathbf{x}) \exp(i \omega t) \label{equ:time-harmonic}
\end{equation}
Substituting this expression into (\ref{equ:maxwell-potential}) and rearranging 
a little results in the
\begin{fancybox}{Time-harmonic potential equation}
    \begin{equation}
     \nabla \times (\mu^{-1} \nabla \times \mathbf{u}) - \epsilon \omega^2 \mathbf{u} = \mathbf{j} \label{equ:maxwell-timeharmonic}
    \end{equation}
\end{fancybox}

\subsection{Weak formulation for the time-harmonic potential equation}
\label{subsec:maxwell-weak}

Equation (\ref{equ:maxwell-timeharmonic}) may be multiplied by a vector-valued
function $\mathbf{v} \in H_{\textrm{curl}}(\Omega)$, where
\begin{equation}
    H_{\textrm{curl}}(\Omega) = \{\mathbf{u} : \Omega \to \mathbb{C},~\text{such that}~\mathbf{u}\in L_2(\mathbb{C})^3, \nabla \times \mathbf{u} \in L_2(\mathbb{C})^3\} \label{equ:h-curl}
\end{equation}
and then integrated over the whole computational domain $\Omega$ to obtain 
\begin{equation}
    \int_{\Omega} (\nabla \times ({\mu^{-1} \nabla \times \mathbf{u}})) \cdot \mathbf{v}
    - \omega^2 \int_{\Omega} \epsilon \mathbf{u} \cdot \mathbf{v} = \int_{\Omega} \mathbf{j} \cdot \mathbf{v} \label{equ:maxwell-weak-initial}
\end{equation}
% !REMINDME: Put derivation in appendix
This may further be simplified (\ref{equ:maxwell-weak-initial}) to (I allow myself
to spare you the details of this computation, but put a proper derivation
in an appendix at the end of the report):
\begin{fancybox}{Weak formulation of the time-harmonic potential equation}
    \begin{equation}
        \int_{\Omega} ({\mu^{-1} \nabla \times \mathbf{u}}) \cdot (\nabla \times \mathbf{v})
        - \omega^2 \int_{\Omega} \epsilon \mathbf{u} \cdot \mathbf{v} 
        = \int_{\Omega} \mathbf{j} \cdot \mathbf{v}
        + \int_{\partial \Omega} \underbrace{(({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{n})}_{= \mathbf{g}} \cdot \mathbf{v}
        \label{equ:maxwell-weak}
    \end{equation}
\end{fancybox}
where $\mathbf{n}$ denotes the surface normal to the boundary $\partial \Omega$
of the computational domain $\Omega$.

Boundary conditions on the electric field $\mathbf{E}$ may be most easily enforced
in a Dirichlet-type fashion through the relation (\ref{equ:electricfield}) and
the assumption (\ref{equ:time-harmonic})
\begin{equation}
    \left.\mathbf{u}\right|_{\Gamma_D} = -\frac{1}{i\omega} \left.\mathbf{E}\right|_{\Gamma_D} \label{equ:dirichlet-boundary}
\end{equation}
Those on the magnetic field $\mathbf{B}$ through a Neumann-type condition following
from (\ref{equ:magneticfield}) and again (\ref{equ:time-harmonic})
\begin{equation}
    \left.\mathbf{g}\right|_{\Gamma_N} = (\mu^{-1} \left.\mathbf{B}\right|_{\Gamma_N}) \times \mathbf{n} \label{equ:neumann-boundary}
\end{equation}

\subsection{Examples}
\label{subsec:examples}

I will now specialize and simplify this weak formulation for three different
applications which will be studied in Section \ref{sec:examples}. To show you
that these problems are intimately related problems, I refer you to Figure \ref{fig:examples}.

\begin{figure}[h]
    \centering
    \input{figures/simple_examples.tex}
    \caption{Schematic visualization of the most trivial case for each of the
    boundary configurations that will be analyzed in Section \ref{sec:examples}.
    The perfectly conducting boundaries are drawn in black, while the imperfectly
    conducting boundary appears dashed. Inlets and exits are left unmarked.}
    \label{fig:examples}
\end{figure}

\subsubsection{Two-dimensional resonant cavity}
\label{subsubsec:cavity}

I refer to a resonant cavity as a region $\Omega$ enclosed by a boundary $\partial \Omega$.
The boundary can be subdivided into one (or more) inlets $\Gamma_N$ and a perfect
conducting wall $\Gamma_D = \partial \Omega \setminus \Gamma_N$
(see Figure \ref{fig:2d-cavity} for an abstract visualization of such a cavity).

\begin{figure}[h]
    \centering
    \input{figures/2d_cavity.tex}
    \caption{An abstract example of a two-dimensional resonant cavity enclosing
    a domain $\Omega$ with a perfectly conducting boundary $\Gamma_D$ and
    featuring a single inlet $\Gamma_N$.}
    \label{fig:2d-cavity}
\end{figure}

% !REMINDME: Why only need test against v_z?!
Suppose the current density $\mathbf{j} \equiv 0$ and orient the coordinate
system in such a way that $\mathbf{u} = u_z \mathbf{e}_z$ and 
$\mathbf{v} = v_z \mathbf{e}_z$. Consequently, the scalar product of the two 
curls in Equation (\ref{equ:equ:maxwell-weak}) simplifies to the scalar product 
of two gradients:
\begin{equation}
    (\mu^{-1} \nabla \times \mathbf{u}) \cdot (\nabla \times \mathbf{v})
    = (\mu^{-1} \nabla u_z) \cdot (\nabla v_z)
\end{equation}
Denote by $g_z$ the component of $\mathbf{g}$ in the $z$-direction along the
inlet $\Gamma_N$. These simplifications allow the conversion of 
(\ref{equ:maxwell-weak}) into the weak formulation for a two-dimensional
resonant cavity
\begin{equation}
    \int_{\Omega} (\mu^{-1} \nabla u_z) \cdot (\nabla v_z)
    - \omega^2 \int_{\Omega} \epsilon u_z v_z
    = \int_{\partial \Omega} g_z v_z \label{equ:maxwell-weak-resonant-cavity}
\end{equation}

% Boundary conditions Dirichlet and Neumann (from Monk)
Now, let $\mathbf{E}$ and $\mathbf{B}$ refer to the electric and magnetic fields inside
the cavity. For now, I distinguish between two types of boundaries:

For the perfectly conducting boundary $\Gamma_D$, treated in \citep{monk}, it holds that
\begin{equation}
    \mathbf{n} \times \mathbf{E} = 0,~~\text{on}~\Gamma_D \label{equ:perfect-conductor-boundary}
\end{equation}
For the boundaries in a two-dimensional resonant cavity (see Figure 
\ref{fig:2d-cavity}), this only holds true if $E_z = 0$, which translates
to the Dirichlet boundary condition $\left.\mathbf{u}\right|_{\Gamma_D} = 0$
in light of (\ref{equ:dirichlet-boundary}).

For the inlet, it is easiest to enforce the boundary condition through the
magnetic field $\mathbf{B}$ in exactly the way proposed in
(\ref{equ:neumann-boundary}) (assuming $\mathbf{n} = -\mathbf{e}_x$ as
will always be the case in Section \ref{sec:examples}, cf. Figure \ref{fig:rectangular_cavity}):
\begin{equation}
    g_z = (({\mu^{-1} \mathbf{B}}) \times (-\mathbf{e}_x))_z = \mu^{-1} B_x,~~\text{on}~\Gamma_N
\end{equation}

\subsubsection{Imperfect conductor}
\label{subsubsec:impedance}

% Additionally impedance boundary condition from Monk
To simulate an imperfect boundary $\Gamma_I$, also called impedance boundary in literature, 
\cite{monk} suggests to replace the integrand $\mathbf{g}$ that appeared in 
(\ref{equ:maxwell-weak}) with
\begin{equation}
    \mathbf{g} = (\mu^{-1} \nabla \times \mathbf{u}) \times \mathbf{n}
    = i \omega \lambda (\mathbf{n} \times \mathbf{u}) \times \mathbf{n}~~\text{on}~\Gamma_D
\end{equation}
with a parameter $\lambda>0$ I will henceforth refer to as the impedance.
Supposing that $\mathbf{u} = u_z \mathbf{e}_z$ and only treating a
two-dimensional domain, this condition simplifies to (using the fact that $\mathbf{n} \perp \mathbf{u}$
and $||\mathbf{n}|| = 1$, so $(\mathbf{n} \times \mathbf{u}) \times \mathbf{n} = \mathbf{u}$,
as is demonstrated in the appendix at the end of this report)
\begin{equation}
    g_z = i \omega \lambda u_z~~\text{on}~\Gamma_D
\end{equation}
Therefore, an impedance boundary can be treated in almost the same way as a
Neumann boundary in the two-dimensional weak formulation (\ref{equ:maxwell-weak-resonant-cavity})
of a resonant cavity.

\subsubsection{Waveguide}
\label{subsubsec:waveguide}

% Just j=0 and 3d, need to discuss boundary conditions
Going back to (\ref{equ:maxwell-weak}) and this time staying in three dimensions,
we again assume no electric current density $\mathbf{j} \equiv 0$ is present.
I suppose that the inlet is located at a constant $x$-value,
such that the surface normal to this inlet is $-\mathbf{e}_x$. Conveniently, the example 
in Section \ref{subsec:examples-dmcwf} happens to be set up in just this way. For an incoming
magnetic field at the inlet $\Gamma_i$ with $\left.\mathbf{B}\right|_{\Gamma_i} = B_0 \mathbf{e}_y$,
we see from (\ref{equ:neumann-boundary}) that this may be modelled by setting
$\left.\mathbf{g}\right|_{\Gamma_i} = - \mu^{-1} B_0 \mathbf{e}_z$.
At the \enquote{exit} $\Gamma_e$, we set $\left.\mathbf{g}\right|_{\Gamma_e} = \boldsymbol{0}$.

\newpage
\section{Finite element approximation with FEniCS}
\label{sec:fem}

Based on the weak formulation corresponding to the time-harmonic potential equation
(\ref{equ:maxwell-weak}), the \acrfull{FEM} can be used to approximate solutions 
to Equation (\ref{equ:maxwell-timeharmonic}).

\subsection{The Galerkin method}
\label{subsec:fem-theory}

% Theory
It is readily seen that the weak formulation (\ref{equ:maxwell-weak}) assumes the shape
\begin{equation}
    \text{Find}~\mathbf{u} \in H_{\textrm{curl}}(\Omega),~\text{such that}~a_{\omega}(\mathbf{u}, \mathbf{v}) = L(\mathbf{v}), ~\forall \mathbf{v} \in H_{\textrm{curl}}(\Omega)
\end{equation}
with the bilinear form 
\begin{equation}
    a_{\omega}(\mathbf{u}, \mathbf{v}) = \int_{\Omega} (\mu^{-1} \nabla \times \mathbf{u}) \cdot (\nabla \times \mathbf{v})
    - \omega^2 \int_{\Omega} \epsilon \mathbf{u} \cdot \mathbf{v} \label{equ:bilinear-form}
\end{equation}
and the linear form 
\begin{equation}
    L(\mathbf{u}) = \int_{\Omega} \mathbf{j} \cdot \mathbf{v} + \int_{\partial \Omega} \mathbf{g} \cdot \mathbf{v} \label{equ:linear-form}
\end{equation}
and the appropriate Hilbert space $H_{\textrm{curl}}(\Omega)$ defined in (\ref{equ:h-curl}).

A sequence of appropriate 
finite dimensional spaces $H_{\textrm{curl}, h}(\Omega)$ is introduced, and the
Galerkin problem is then formulated as (see \cite{numapproxPDEs} for details)
\begin{fancybox}{Galerkin problem for the time-harmonic potential equation}
    \begin{equation}
        \text{Find}~\mathbf{u}_h \in H_{\textrm{curl},h}(\Omega),~\text{such that}~a_{\omega}(\mathbf{u}_h, \mathbf{v}_h) = L(\mathbf{v}_h), ~\forall \mathbf{v} \in H_{\textrm{curl}, h}(\Omega) \label{equ:galerkin-problem}
    \end{equation}
\end{fancybox}
One class of finite elements, the Nédélec elements of the first
kind, are particularly well suited for discretizing curl-problems of the type
we have derived in Section \ref{sec:maxwell} (see \cite{monk}).

\subsection{Numerical approximation of \acrshort{PDE}s using FEniCS}
\label{subsec:fem-demo}

% Demonstration
FEniCS\footnote{\url{https://fenicsproject.org/}} bundles a collection of Python
modules designed to automate solving a \acrfull{PDE}.
Inspired by the demonstrations encountered in \cite{fenics}, I will now guide you
through a simple example, relevant to the context of this report, in order to
show how the process of obtaining
approximate solutions to \acrshort{PDE}s with FEniCS.

Consider the time-harmonic potential equation (\ref{equ:maxwell-timeharmonic})
with the computational domain $\Omega$ being a cubic cavity with an inlet $\Gamma_N$
on one of its sides, but all other boundaries being perfect conductors.
Set $\mu = \epsilon = 1$ and $\mathbf{j} = 0$ for simplicity.

The \texttt{fenics} package is imported along with \texttt{numpy} and
\texttt{matplotlib.pyplot} for array manipulation and visualization respectively.
\lstinputlisting[firstnumber=1, firstline=2, lastline=3]{code/fenics_example.py}

A mesh for the cubic cavity $\Omega$ is generated by dividing the cube into a
$10\times10\times10$ grid, whose cells are again subdivided into tetrahedrons.
\lstinputlisting[firstnumber=5, firstline=6, lastline=7]{code/fenics_example.py}

Our function space $H_{\textrm{curl},h}(\Omega)$ is composed using piecewise
linear Nédélec elements of the first kind.
\lstinputlisting[firstnumber=9, firstline=10, lastline=10]{code/fenics_example.py}

The inlet is introduced at $x = 0$.
\lstinputlisting[firstnumber=12, firstline=13, lastline=15]{code/fenics_example.py}

All other boundaries are perfectly conducting walls.
\lstinputlisting[firstnumber=17, firstline=18, lastline=20]{code/fenics_example.py}

A mesh function is used to identify the different boundaries. It evaluates to
0, if a vertex is not on any boundary; 1 if the vertex is a the inlet; and 2 if
the vertex sits on a perfectly conducting boundary.
\lstinputlisting[firstnumber=22, firstline=23, lastline=26]{code/fenics_example.py}

For Nédélec elements of the first kind, (\ref{equ:perfect-conductor-boundary})
is enforced through
\lstinputlisting[firstnumber=28, firstline=29, lastline=30]{code/fenics_example.py}

Let $\mathbf{g} = \mathbf{e}_z$ in (\ref{equ:neumann-boundary}), which corresponds
to a magnetic field $\mu^{-1} \mathbf{B} = \mathbf{e}_y$.
\lstinputlisting[firstnumber=32, firstline=33, lastline=34]{code/fenics_example.py}

Trial and test functions for the function space $H_{\mathrm{curl},h}(\Omega)$ are instantiated.
\lstinputlisting[firstnumber=36, firstline=37, lastline=38]{code/fenics_example.py}

The linear form (\ref{equ:linear-form}) is assembled.
\lstinputlisting[firstnumber=40, firstline=41, lastline=41]{code/fenics_example.py}

The stiffness matrix (i.e. the first term in the bilinear form (\ref{equ:bilinear-form}))
is assembled, and the Dirichlet boundary conditions are applied.
\lstinputlisting[firstnumber=43, firstline=44, lastline=45]{code/fenics_example.py}

The mass matrix (i.e. the second term in the bilinear form (\ref{equ:bilinear-form}))
is assembled, and the Dirichlet boundary conditions are accounted for by setting
all rows and columns corresponding to degrees of freedom on the perfectly conducting
boundary to zero.
\lstinputlisting[firstnumber=47, firstline=48, lastline=49]{code/fenics_example.py}

A function to compute an approximation of the $L_2(\Omega)$-norm of a solution
to the system can be created.
\lstinputlisting[firstnumber=51, firstline=52, lastline=54]{code/fenics_example.py}

Finally, for 200 uniformly spaced frequencies $\omega \in [6.2, 6.8]$, the 
approximate solution to the cubic cavity at each of these frequencies is
computed and its $L_2(\Omega)$-norm memorized for later.
\lstinputlisting[firstnumber=56, firstline=57, lastline=62]{code/fenics_example.py}

What results is an approximation of the frequency response in the $L_2(\Omega)$-norm
for the cubic cavity (see Figure \ref{fig:fenics-demonstration}). 
\begin{figure}[h]
    \centering
    \input{plots/fenics_demonstration.pgf}
    \caption{Frequency response in the $L_2(\Omega)$-norm of a cubic cavity with
    one face acting as an inlet and all others as perfectly conducting boundaries.
    At resonant frequencies, the $L_2(\Omega)$-norm theoretically tends to infinity.
    Numerically, they appear as finite peaks in the frequency response.}
    \label{fig:fenics-demonstration}
\end{figure}

\newpage
\section{Minimal rational interpolation for the time-harmonic Maxwell's equations}
\label{sec:mri}

% General idea 
Let $\mathbf{u} : \mathbb{C} \to \mathbb{C}^3$. Given \enquote{snapshots} of the
function $\mathbf{u}(\omega_j)$ at $\omega_j$ for $j \in \{1, \dots, S\}$, the
goal is to find a surrogate that locally (i.e. near $\omega_1, \dots, \omega_S$)
satisfies
\begin{equation}
    \mathbf{\tilde{u}}(\omega) \approx \mathbf{u}(\omega)
\end{equation}
This may be achieved using the \acrfull{MRI} technique, which I will motivate,
discuss, and extend in the following.

\subsection{Motivation}
\label{subsec:motivation}

In the most simple case (dropping all constants), equations of the type
(\ref{equ:maxwell-timeharmonic}) take the form
\begin{equation}
    \nabla \times (\nabla \times \mathbf{u}) - \omega^2 \mathbf{u} = \mathbf{j}
    \label{equ:maxwell-timeharmonic-simple}
\end{equation}
Writing the double-curl operator in terms of a matrix $\mathbf{\underline{A}}$
allows for an expression of the solution $\mathbf{u}$ to (\ref{equ:maxwell-timeharmonic-simple})
as
\begin{equation}
    \mathbf{u} = (\mathbf{\underline{A}} - \omega^2)^{-1} \mathbf{j}
\end{equation}
The eigenvalue decomposition $\mathbf{\underline{A}} = \mathbf{\underline{V}}
~ \boldsymbol{\underline{\Lambda}} ~ \mathbf{\underline{V}}^H$
leads to a similar form as the one proposed in \cite{helmholtz-motivation}
\begin{equation}
    \mathbf{u} = \mathbf{\underline{V}} (\boldsymbol{\underline{\Lambda}} - \omega^2 \boldsymbol{\underline{1}})^{-1} \mathbf{\underline{V}}^H \mathbf{j} 
    = \sum_i \frac{\mathbf{v}_i \mathbf{v}_i^H \mathbf{j}}{\lambda_i - \omega^2} \label{equ:motivation}
    %= \sum_i \frac{\mathbf{r}_i}{\lambda_i - \omega^2} \label{equ:motivation}
\end{equation}
This follows from the fact that $\boldsymbol{\underline{\Lambda}}$ is diagonal,
hence also $(\boldsymbol{\underline{\Lambda}} - \omega^2 \boldsymbol{\underline{1}})^{-1}$.
Here, the diagonal elements of $\boldsymbol{\underline{\Lambda}}$ are denoted with 
$\lambda_i$ (the eigenvalues of $\mathbf{\underline{A}}$) and the columns of
$\mathbf{\underline{V}}$ with $\mathbf{v}_i$ (the eigenvectors of $\mathbf{\underline{A}}$).

% !REMINDME: This is not really phrased academically yet...
With the expression of the solution $\mathbf{u}$ in terms of a rational polynomial
function (see (\ref{equ:motivation})), we can motivate why rational interpolation
is a valid approach for approximating $\mathbf{u}$. Some alternatives such as polynomial
interpolation are not as capable to model the singularities at the resonant
frequencies $\omega^2 = \lambda_i$.

Consequently, the goal is to find rational surrogates of the form
\begin{equation}
    \mathbf{\tilde{u}}(\omega) = \frac{\mathbf{P}(\omega)}{Q(\omega)}
\end{equation}
with
\begin{equation}
    \mathbf{P}(\omega) = \sum_i \frac{\mathbf{p}_i}{\omega - \omega_i}
\end{equation}
and
\begin{equation}
    Q(\omega) = \sum_i \frac{q_i}{\omega - \omega_i} \label{equ:surrogate-denomniator}
\end{equation}
in the barycentric representation.

\subsection{Minimal rational interpolation}
\label{subsec:MRI}

In the following, I denote with
\begin{equation}
    \langle u, v \rangle_M = \mathbf{u}^H \mathbf{\underline{M}} \mathbf{v} \approx \int_{\Omega} u v \label{equ:matrix-inner-product}
\end{equation}
the finite element approximation of the inner product in $L_2(\Omega)$.
$\mathbf{u}$ and $\mathbf{v}$ are the vectors collecting the vertex values for
all degrees of freedom, while $\mathbf{\underline{M}}$ is the representation matrix
of the inner product in the vertex basis. Similarly, let
\begin{equation}
    ||u||_M = \sqrt{\langle u, u \rangle} \approx ||u||_{L_2(\omega)} \label{equ:matrix-norm}
\end{equation}

% Algorithm (last column SVD is definition of MRI)
For completeness, I state the strategy for numerically computing the \acrfull{MRI} 
for a collection of snapshots sampled from the target $\mathbf{u}$ \citep{greedyMRI}
in Algorithm \ref{alg:MRI}. The heart of the algorithm consists in computing the
\acrfull{SVD} of the so-called Gramian matrix, and using the last
left-singular vector to build the surrogate.

\begin{algorithm}
    \caption{Minimal rational interpolation} \label{alg:MRI}
    \input{algorithms/MRI.tex}
\end{algorithm}

\subsection{Greedy minimal rational interpolation}
\label{subsec:gMRI}

A question that arises from the previous section is what the ideal choice of
support points $\omega_1, \dots, \omega_S$ is: How many support points are
required to achieve a good enough approximation and how should the supports
be distributed when given a target domain. The \acrfull{gMRI} algorithm 
\citep{shortMRI} tackles both questions simultaneously.

In brief, the algorithm starts with a set of candidate support points
$\Omega_{\mathrm{test}} = \{\omega_i\}_{i=1}^M$, for which we can guarantee
to find an approximate solution to (\ref{equ:galerkin-problem}). 
From the $\Omega_{\mathrm{test}}$ a subset is chosen (usually the smallest and
largest element), and (\ref{equ:galerkin-problem}) is solved for these two initial
supports. Using these solutions, a rational surrogate is built with
\acrshort{MRI} (Algorithm \ref{alg:MRI}). Motivated by the expression for the
upper bound on the residual norm demonstrated in \cite{theoryMRI}, new support
points are chosen as the minimizers of the denominator polynomial $Q(\omega)$
and added to the set of supports. Support points are iteratively added until
the relative error norm drops below a certain tolerance.

The \acrshort{gMRI} algorithm can be found in Algorithm \ref{alg:gMRI}.

\begin{algorithm}
    \caption{Greedy minimal rational interpolation} \label{alg:gMRI}
    \input{algorithms/gMRI.tex}
\end{algorithm}

\subsection{Properties of rational interpolants in barycentric coordinates}
\label{subsec:properties}

% Interpolation property (in barycentric expansion, l'Hôpital whatever)
The rational surrogate $\mathbf{\tilde{u}}$ obtained with Algorithm \ref{alg:MRI}
can be rewritten as
\begin{equation}
    \mathbf{\tilde{u}}(\omega)
    = \sum_{j=1}^S \prod_{\substack{i=0 \\ i \neq j}}^S (\omega - \omega_i) q_j \mathbf{u}(\omega_j)
    / \sum_{j=1}^S \prod_{\substack{i=0 \\ i \neq j}}^S (\omega - \omega_i) q_j
\end{equation}
Hence, if the rational surrogate $\mathbf{\tilde{u}}$ is evaluated at one of the
interpolation nodes $\omega_i$, the snapshot $\mathbf{u}(\omega_i)$ supplied to 
the \acrshort{MRI} algorithm is recovered. This shows that the rational surrogate
satisfies the interpolation property.

\subsection{Finding roots of rational functions}
\label{subsec:roots}
% Rational root finding 

If the rational surrogate $\mathbf{\tilde{u}}$ is evaluated in a zero
$\omega^\ast$ of the denominator $Q(\omega^\ast) = 0$, we observe a pole,
provided $P(\omega^\ast)$ does not also vanish in that frequency.
$\omega^\ast$ is referred to as a resonant frequency.

In order to find the approximate resonant frequencies of a system,
we simply need to perform the following steps:

\begin{enumerate}
    \item Compute the rational surrogate using \acrshort{MRI} or \acrshort{gMRI}.
    \item Determine the zeros of the denominator $Q(\omega)$ of the surrogate
\end{enumerate}

The first step was already elaborated upon in Sections \ref{subsec:MRI} and \ref{subsec:gMRI}.
Finding the zeros of a rational function of the form (\ref{equ:surrogate-denominator})
can be elegantly converted to an eigenvalue problem \citep{klein}:

Define
\begin{equation}
    v_i = (\omega - \omega_i)^{-1}
\end{equation}
We want to find $\omega$, such that
\begin{equation}
    0 = Q(\omega) = \sum_{i=1}^S q_i v_i(\omega)
\end{equation}
This can be equivalently expressed as the generalized eigenvalue problem
\begin{equation}
    \mathbf{\underline{A}} \mathbf{u} = \omega \mathbf{\underline{B}} \mathbf{u} \label{equ:eigenvalue-problem}
\end{equation}
with
\begin{equation}
    \mathbf{\underline{A}} = \begin{pmatrix}
        0 & q_1 & q_2 & \dots & q_S \\
        1 & \omega_1 & & & \\
        1 & & \omega_2 & & \\ 
        \vdots & & & \ddots & \\ 
        1 & & & & \omega_S
    \end{pmatrix} ~~\text{and}~~
    \mathbf{\underline{B}} = \begin{pmatrix}
        0 & & & & \\
         & 1 & & & \\
         & & 1 & & \\ 
        \vdots & & & \ddots & \\ 
         & & & & 1
    \end{pmatrix}\label{equ:root-finding}
\end{equation}

\subsection{Optimization tricks for greedy minimal rational interpolation}
\label{subsec:optimization}
% Optimization tweaks

There exist many ways of improving the efficiency and/or capability of the
\acrshort{gMRI} algorithm \cite{davidePHD}. In the following, I will present
a small collection of them.

\subsubsection{Additive Householder decomposition}
\label{subsubsec:householder}
% -> Householder sequential algorithm instead of full Gramian

Algorithm \ref{alg:MRI} requires the computation of the \acrfull{SVD}
of the Gramian matrix $\mathbf{\underline{G}}$ in order to build the rational
surrogate. A more efficient and better conditioned \cite{davidePHD} alternative is to compute
the QR decomposition of the snapshot matrix $\mathbf{\underline{U}} = [\mathbf{u}(\omega_1), \dots, \mathbf{u}(\omega_S)]$.
Since
\begin{equation}
    \mathbf{\underline{G}} = \mathbf{\underline{U}}^H \mathbf{\underline{M}}~\mathbf{\underline{U}} \label{equ:gramian-matrix}
\end{equation}
with the matrix $\mathbf{\underline{M}}$ representing the finite element 
inner product in $L_2(\Omega)$ in the basis of the mesh vertices.
A QR decomposition with respect to the inner product
$\langle \mathbf{u}, \mathbf{v} \rangle_M = \mathbf{u}^H \mathbf{\underline{M}} \mathbf{v}$
yields $\mathbf{\underline{U}} = \mathbf{\underline{Q}}~\mathbf{\underline{R}}$
with $\mathbf{\underline{Q}}^H \mathbf{\underline{M}}~\mathbf{\underline{Q}} = \boldsymbol{\underline{1}}$.
When plugging this into (\ref{equ:gramian-matrix}) one sees
\begin{equation}
    \mathbf{\underline{G}} = (\mathbf{\underline{Q}}~\mathbf{\underline{R}})^H \mathbf{\underline{M}} 
    (\mathbf{\underline{Q}}~\mathbf{\underline{R}}) = \mathbf{\underline{R}}^H~\mathbf{\underline{R}}
    \label{equ:gramian-QR}
\end{equation}

Let the \acrshort{SVD} of $\mathbf{\underline{R}}$ be 
\begin{equation}
    \mathbf{\underline{R}} = \mathbf{\underline{W}}~\mathbf{\underline{S}}~\mathbf{\underline{V}}^H \label{equ:qr-decomposition}
\end{equation}
Inserting this into (\ref{equ:gramian-QR}) results in
\begin{equation}
    \mathbf{\underline{G}} = (\mathbf{\underline{W}}~\mathbf{\underline{S}}~\mathbf{\underline{V}}^H)^H \mathbf{\underline{W}}~\mathbf{\underline{S}}~\mathbf{\underline{V}}^H
    = \mathbf{\underline{V}}~\mathbf{\underline{S}}^2\mathbf{\underline{V}}^H
    \label{equ:gramian-SVD}
\end{equation}
which coincides with the \acrshort{SVD} of the Gramian matrix $\mathbf{\underline{G}}$
if we take the square root of the singular values.

There is one additional benefit to taking the route via the \acrshort{SVD} of
$\mathbf{\underline{R}}$ instead of $\mathbf{\underline{G}}$
for building the surrogate: When extending the snapshot matrix by an additional
snapshot $\mathbf{u}(\omega_{S+1})$, the resulting triangular matrix $\mathbf{\underline{R}}^{(S+1)}$
from a QR decomposition on this extended snapshot matrix only differs from the 
(usually already computed) matrix $\mathbf{\underline{R}}^{(S)}$ only in the last column.
Thus, it is possible to reuse many results obtained in a previous iterations of
the \acrshort{gMRI} algorithm and therefore significantly increase computational
efficiency.

I developed such an additive QR decomposition in Algorithm \ref{alg:householder},
which results from an adaption of the Householder triangularization algorithm
found in \citep{householder}. In essence, this algorithm takes the triangular
matrix $\mathbf{\underline{R}}$, orthonormal matrix $\mathbf{\underline{E}}$,
and Householder matrix $\mathbf{\underline{V}}$ and extends each of them according
to the additional snapshots supplied to the algorithm.

\begin{algorithm}
    \caption{Additive Householder triangularization} \label{alg:householder}
    \input{algorithms/householder.tex}
\end{algorithm}

% -> Twice is enough?

\subsubsection{Stability of singular value decomposition}
\label{subsubsec:svd}
% -> Check stability of build with SVDs (maybe also mention G / R difference)
The stability of the build of the rational surrogate using \acrshort{MRI}
can be checked by analyzing the singular values $\sigma_1, \dots, \sigma_S$ 
obtained from performing the \acrshort{SVD}. Assume these values to be
ordered in descending order, which the Python package
\texttt{numpy} automatically does when computing the \acrshort{SVD} of a matrix. 
The conditioning of the problem may be measured with the relative
spectral gap \cite{davidePHD}
\begin{equation}
    \frac{\sigma_{S-1} - \sigma_S}{\sigma_1 - \sigma_S}
\end{equation}

\subsubsection{Alternative representations of the surrogate}
\label{subsubsec:u-ring}
% -> Model order reduction techniques (u_ring, error computation, ...)
Denote with $\mathbf{\underline{U}} = [\mathbf{u}(\omega_1), \dots, \mathbf{u}(\omega_S)]$
the snapshot matrix. Let 
\begin{equation}
    \accentset{\circ}{\mathbf{u}}(\omega) = \sum_{j=1}^S \frac{q_j \mathbf{e}_j}{\omega - \omega_j}
    / \sum_{j=1}^S \frac{q_j}{\omega - \omega_j} \label{equ:u-ring}
\end{equation}
with the canonical basis vectors $\{ \mathbf{e}_j \}_j$, and denote
$\accentset{\circ}{\mathbf{\underline{U}}} = [\accentset{\circ}{\mathbf{u}}(\omega_1), \dots, \accentset{\circ}{\mathbf{u}}(\omega_S)]$
Inspecting the rational surrogate (defined in Algorithm \ref{alg:MRI}) closely,
one can see that the rational surrogate can be recovered from $\accentset{\circ}{\mathbf{u}}$
via
\begin{equation}
    \mathbf{\tilde{u}}(\omega) = \mathbf{\underline{U}} \accentset{\circ}{\mathbf{u}}(\omega)
\end{equation}
Therefore, provided we know the snapshot matrix, a rational surrogate is
fully characterized by just $S$ numbers $\{q_1, \dots, q_S\}$
and the locations of the interpolation nodes $\{\omega_1, \dots, \omega_S\}$.

Additionally, let
\begin{equation}
    \mathbf{\hat{u}}(\omega) = \mathbf{\underline{R}} \accentset{\circ}{\mathbf{u}}(\omega) \label{equ:u-hat}
\end{equation}
with $\mathbf{\underline{R}}$ being the triangular matrix stemming from the QR decomposition 
of the snapshot matrix $\mathbf{\underline{U}} = \mathbf{\underline{Q}} ~ \mathbf{\underline{R}}$.
The original rational surrogate can again be recovered via
\begin{equation}
    \mathbf{\tilde{u}}(\omega) = \mathbf{\underline{Q}} \mathbf{\hat{u}}(\omega)
\end{equation}
$\mathbf{\hat{u}}(\omega)$ provides us with a simplified alternative to the
computation of the error in \acrshort{gMRI} (Algorithm \ref{alg:gMRI}).

% NEED TO REWORK THIS A LOOOT!!!
\begin{equation}
    ||\mathbf{u}_{t+1}(\omega_{t+1}) - \mathbf{\tilde{u}}_{t+1}(\omega_{t+1})||_M
    = ||\mathbf{\underline{Q}} \mathbf{r}_{t+1} - \mathbf{\underline{Q}}\mathbf{\hat{u}}_{t+1}(\omega_{t+1})||_M
    = ||\mathbf{r}_{t+1} - \mathbf{\hat{u}}_{t+1}(\omega_{t+1})||_M
\end{equation}
where $\mathbf{r}_{t+1}$ is the last column in $\mathbf{\underline{R}}^{(t+1)}$,
he triangular matrix from the $(t+1)$-th step in the additive Housholder decomposition
(Algorithm \ref{alg:householder}).
\begin{equation}
    ||\mathbf{u}(\omega)||_M^2 \approx ||\mathbf{\tilde{u}}(\omega)||_M^2
    = ||\mathbf{\underline{U}} \accentset{\circ}{\mathbf{u}}(\omega)||_M^2
    = \accentset{\circ}{\mathbf{u}}(\omega)^H \underbrace{\mathbf{\underline{U}}^H \mathbf{\underline{M}} \mathbf{\underline{U}}}_{= \mathbf{\underline{G}} = \mathbf{\underline{R}}^H \mathbf{\underline{R}}} \accentset{\circ}{\mathbf{u}}(\omega)
    = \mathbf{\hat{u}}(\omega)^H \mathbf{\hat{u}}(\omega)
    = ||\mathbf{\hat{u}}(\omega)||^2
\end{equation}
Thus, computing the relative error norm can be approximated by only computing
Euclidean norms.

\newpage
\section{Examples}
\label{sec:examples}

\subsection{Two-dimensional rectangular cavity}
\label{subsec:examples-rectangularcavity}

\begin{figure}[h]
    \centering
    \input{figures/rectangular_cavity.tex}
    \caption{TODO.}
    \label{fig:rectangular_cavity}
\end{figure}

% Exploratory plots

\begin{figure}[ht]
    \centering
    \begin{subfigure}{\textwidth}
        \includegraphics{plots/rectangular_cavity_mode1.pdf}
        \caption{First resonant frequency $\omega = 3.159$.}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \includegraphics{plots/rectangular_cavity_mode5.pdf}
        \caption{Fifth resonant frequency $\omega = 4.675$.}
    \end{subfigure}
    \caption{Caption.}
    \label{fig:rectangular-cavity-modes}
\end{figure}

% Rational interpolation demonstration
For $||\mathbf{u}||_{L_2(\Omega)}^2 = \int_{\Omega} ||\mathbf{u}||^2$

\begin{figure}[ht]
    \centering
    \input{plots/rectangular_cavity_norms.pgf}
    \caption{Caption.}
    \label{fig:rectangular-cavity-norms}
\end{figure}

\begin{figure}[ht]
    \centering
    \input{plots/rectangular_cavity_errorprogression.pgf}
    \caption{Caption.}
    \label{fig:rectangular-cavity-errorprogression}
\end{figure}


% Analytical and numerical root finding
Analytical eigenfrequencies
\begin{equation}
    \omega_{n, m} = \pi \sqrt{\left(\frac{2n + 1}{2L_x}\right)^2 + \left(\frac{m}{L_y}\right)^2},
    ~n \in \{0, 1, \dots\}, ~m \in \{1, 2, \dots \} \label{equ:analytical-eigenmodes}
\end{equation}
Numerical eigenfrequencies, solve generalized (symmetric) eigenvalue problem
\begin{equation}
    \mathbf{\underline{K}} \mathbf{u} = \omega^2 \mathbf{\underline{M}} \mathbf{u}
    \label{equ:numerical-eigenmodes}
\end{equation}
% maybe also talk about removing boundary indices
\begin{table}[ht]
    \caption{Comparison eigsh and gMRI.}
    \label{tab:rectangular_cavity_comparison}
    \input{tables/rectangular_cavity_comparison.tex}
\end{table}

% Problems with non-resonant solutions suppressed by the boundary integral
Take $\{ \mathbf{u}_j, \omega_j^2 \}_j$ be the resonant modes, i.e. solutions to 
the eigenvalue problem (\ref{equ:numerical-eigenmodes}), such that
\begin{equation}
    \mathbf{\underline{K}} \mathbf{u}_j = \omega_j^2 \mathbf{\underline{M}} \mathbf{u}_j
    \label{equ:eigen-solution}
\end{equation}
Adding a source term $\mathbf{f}$ 
\begin{equation}
    \mathbf{\underline{K}} \mathbf{u} - \omega^2 \mathbf{\underline{M}} \mathbf{u} = \mathbf{f}
\end{equation}
If $\mathbf{u}$ is expressed in terms of the basis $\{ \mathbf{u}_j \}_j$, i.e.
$\mathbf{u} = \sum_j \alpha_j \mathbf{u}_j$
\begin{equation} 
    \sum_j \alpha_j (\mathbf{\underline{K}} \mathbf{u}_j - \omega^2 \mathbf{\underline{M}} \mathbf{u}_j) = \mathbf{f}
\end{equation}
Using (\ref{equ:eigen-solution})
\begin{equation}
    \sum_j \alpha_j (\omega_j^2 - \omega^2) \mathbf{\underline{M}} \mathbf{u}_j = \mathbf{f}
\end{equation}
from which we can take the scalar product with $\mathbf{u}_j^H$ to obtain
% WHY SHOULD THIS BE A BASIS (DOES IT SPAN?), AND WHY M-ORTHONORMAL
\begin{equation}
    \alpha_j = \frac{\mathbf{u}_j^H \mathbf{f}}{\omega_j^2 - \omega^2}
\end{equation}
If $\mathbf{u}_j^H \mathbf{f} = 0$, then the resonant mode at $\omega_j$ is 
suppressed (fine with MRI, but eigsh will detect a resonant mode).

\begin{figure}[ht]
    \centering
    \input{plots/rectangular_cavity_suppression.pgf}
    \caption{Caption.}
    \label{fig:rectangular-cavity-suppression}
\end{figure}


% Problems with linearly combinable solutions -> Use cubby to perturb waveguide
For $||\mathbf{u}||_{L_2(\Gamma)}^2 = \int_{\Gamma} ||\mathbf{u}||^2$

\subsection{Imperfectly conducting boundaries}
\label{subsec:examples-impedance}
% argmin |Q| only valid in undamped regime
\begin{figure}[ht]
    \centering
    \includegraphics{plots/imperfect_conductor_solution.pdf}
    \caption{$\omega = 3.5$.}
    \label{fig:imperfect-conductor-solution}
\end{figure}


\begin{figure}[ht]
    \centering
    \input{plots/imperfect_conductor_norms.pgf}
    \caption{Caption.}
    \label{fig:imperfect-conductor-norms}
\end{figure}

% Numerical eigenfrequencies
Numerical eigenfrequencies, solve
\begin{equation}
    (\mathbf{\underline{K}} - i \omega \mathbf{\underline{I}} - \omega^2 \mathbf{\underline{M}}) \mathbf{u} = 0
\end{equation}
Define $\mathbf{v} = \omega \mathbf{u}$, so that we may write this as the
generalized eigenvalue problem
\begin{equation}
    \begin{bmatrix}
         & \boldsymbol{\underline{1}} \\
        \mathbf{\underline{K}} & -i \mathbf{\underline{I}}
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{u} \\
        \mathbf{v}
    \end{bmatrix}
    =
    \omega
    \begin{bmatrix}
        \boldsymbol{\underline{1}} & \\
         & \boldsymbol{\underline{M}}
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{u} \\
        \mathbf{v}
    \end{bmatrix}
\end{equation}
which is, however, no longer Hermitian (LHS chosen as \enquote{diagonal} as possible).
% Pole plot

\begin{figure}[ht]
    \centering
    \input{plots/imperfect_conductor_eigfreqs.pgf}
    \caption{Spurious resonant frequency far away from others and definitely 
    not of interest for this problem, but indeed for rational surrogate.}
    \label{fig:imperfect-conductor-eigfreqs}
\end{figure}

\begin{table}[ht]
    \caption{Comparison eigsh and gMRI.}
    \label{tab:imperfect-conductor-comparison}
    \input{tables/imperfect_conductor_comparison.tex}
\end{table}

\subsection{Dual mode circular waveguide filter}
\label{subsec:examples-dmcwf}

% Describe geometry and physical meaning

\begin{figure}[h]
    \centering
    \input{figures/DMCWF.tex}
    \caption{Dual-mode circular waveguide filter. \cite{DMCWF-Dimensions}
    $W_C=43.87$ mm, $D_C=28.0$ mm, $L_B=43.87$ mm, $W_B=19.05$ mm, $H_B=9.525$ mm,
    $L_B=20.0$ mm, $W_S=10.05$ mm, $H_S=3.0$ mm, $W_A=2.0$ mm, $H_A=3.375$ mm,
    $L_A=2.825$ mm, thickness of all irises $2.0$ mm, screws half way up
    the cavity horizontal tuning screws with depth $3.82$ mm
    and coupling screws at angles $\pm 45^{\circ}$ with depth $3.57$ mm.}
    \label{fig:DMCWF}
\end{figure}

% Modeling process cite rubia
Modeled according to \cite{DMCWF-Dimensions} in the computer-aided design 
modeler software application FreeCAD\footnote{\url{https://www.freecadweb.org/}}.
Mesh generated using Gmsh\footnote{\url{https://gmsh.info/}}. 5 smoothing
steps, element size factor of 0.2 and Delaunay 3D meshing algorithm.
The mesh was refined around critical components such as the screws and irises
using transfinite curves.
Conversion using meshio\footnote{\url{https://github.com/nschloe/meshio}} to .xml
format which can be understood by FEniCS.

% Scattering coefficient
\cite{shortMRI}
\begin{equation}
    \mathbf{\underline{S}}(\omega) = \mathbf{\underline{1}}
    - 2\left( \mathbf{\underline{1}} + i \frac{\omega}{2\pi}
    \sqrt{\frac{1 - (\omega_c / \omega_0)^2}{1 - (\omega_c / \omega)^2}} 
    \mathbf{\underline{F}}^H \mathbf{\underline{U}}(\omega) \right)^{-1}
\end{equation}

with $\mathbf{\underline{F}} = [\mathbf{f}_1, \mathbf{f}_2]$ and
$\mathbf{\underline{U}} = [\mathbf{u}_1, \mathbf{u}_2]$ with $f_1$ the term
resulting when forcing from one side producing the solution $\mathbf{u}_1$,
and the $f_2$ when forcing from the other side to produce $\mathbf{u}_2$.

\begin{figure}[ht]
    \centering
    \input{plots/circular_waveguide_scattering.pgf}
    \caption{Caption.}
    \label{fig:circular-waveguide-scattering}
\end{figure}

\begin{figure}[ht]
    \centering
    \input{plots/circular_waveguide_error.pgf}
    \caption{Caption.}
    \label{fig:circular-waveguide-error}
\end{figure}

\newpage
\section{Conclusion and outlook}
\label{sec:conclusion}

\newpage
\bibliography{biblio.bib}

\newpage
\section{Appendix}
\label{sec:appendix}

\subsection{Detailed derivation for the weak formulation of the time-harmonic potential equation}
\label{subsec:derivation}

% !REMINDME: Levi-Civita tensor explanations.
The goal is to rewrite the curl-integral on the left-hand side of 
(\ref{equ:maxwell-weak-initial}):
\begin{equation}
    \int_{\Omega} (\nabla \times (\mu^{-1} \nabla \times \mathbf{u})) \cdot \mathbf{v} \label{equ:maxwell-weak-initial-LHS}
\end{equation}
In order to simplify the curls and apply the Gauss theorem, I first show
the following vector calculus identity:
\begin{fancybox}{Curl product rule}
    \begin{equation}
        (\nabla \times \mathbf{a}) \cdot \mathbf{b} = \nabla \cdot (\mathbf{a} \times \mathbf{b}) + \mathbf{a} \cdot (\nabla \times \mathbf{b}) \label{equ:vector-calculus}
    \end{equation}
\end{fancybox}
% !REMINDME: Appropriate spaces
where $\mathbf{a}$, $\mathbf{b}$ are vector-value functions. The completely
antisymmetric tensor $\varepsilon_{ijk}$, frequently referred to as the
Levi-Civita tensor, may be employed to rewrite the components of the
curl of a vector-function $\mathbf{a}$ as the sum
% !REMINDME: Maybe lemma and proof formatting
\begin{equation}
    (\nabla \times \mathbf{a})_k = \sum_i \sum_j \varepsilon_{ijk} \partial_i u_j
\end{equation}
where $\partial_i$ denotes the partial derivative with respect to the $i$-th coordinate
direction. This yields
\begin{align}
    (\nabla \times \mathbf{a}) \cdot \mathbf{b} &= \sum_k (\nabla \times \mathbf{a})_k b_k \notag \\ 
    &= \sum_k (\sum_i \sum_j \varepsilon_{ijk} \partial_i a_j) b_k \notag \\ 
    &= \sum_k \sum_i \sum_j \partial_i (\varepsilon_{ijk} a_j b_k) - \sum_k \sum_i \sum_j a_j (\varepsilon_{ijk} \partial_i b_k) \notag \\ 
    &= \sum_k \sum_i \sum_j \partial_i (\varepsilon_{jki} a_j b_k) - \sum_k \sum_i \sum_j a_j ((-\varepsilon_{ikj}) \partial_i b_k) \notag \\ 
    &= \sum_i \partial_i (\mathbf{a} \times \mathbf{b})_i + \sum_j u_j (\nabla \times \mathbf{b})_j \notag \\ 
    &= \nabla \cdot (\mathbf{a} \times \mathbf{b}) + \mathbf{a} \cdot (\nabla \times \mathbf{b}) \label{equ:curlidentity} 
\end{align}
by expressing the scalar product as a component-sum, using the product rule and
applying the symmetry and anti-symmetry properties of the Levi-Civita tensor.
Now the identity (\ref{equ:vector-calculus}) to (\ref{equ:maxwell-weak-initial-LHS})
together with Gauss' theorem gives
\begin{align}
    \int_{\Omega} (\nabla \times ({\mu^{-1} \nabla \times \mathbf{u}})) \cdot \mathbf{v} &=
    \int_{\Omega} \nabla \cdot (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{v})
    + \int_{\Omega} ({\mu^{-1} \nabla \times \mathbf{u}}) \cdot (\nabla \times \mathbf{v}) \notag \\
    &= \int_{\partial \Omega} (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{v}) \cdot \mathbf{n}
    + \int_{\Omega} ({\mu^{-1} \nabla \times \mathbf{u}}) \cdot (\nabla \times \mathbf{v}) \notag \\
\end{align}

For later convenience, the boundary integral can further be simplified using the
\begin{fancybox}{Commutative behavior of the scalar triple product}
    \begin{equation}
        (\mathbf{a} \times \mathbf{b}) \cdot \mathbf{c} = - (\mathbf{a} \times \mathbf{c}) \cdot \mathbf{b} \label{equ:vector-algebra}
    \end{equation}
\end{fancybox}
This identity follows immediately from a small manipulation with the Levi-Civita
tensor:
\begin{align}
    (\mathbf{a} \times \mathbf{b}) \cdot \mathbf{c} &= \sum_k (\sum_i \sum_j \varepsilon_{ijk} a_i b_j) c_k \notag \\
     &= \sum_j (\sum_i \sum_k (-\varepsilon_{ikj}) a_i c_k) b_j \notag \\ 
     &= - (\mathbf{a} \times \mathbf{c}) \cdot \mathbf{b} 
\end{align}
The boundary integral becomes 
\begin{equation}
    \int_{\partial \Omega} (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{v}) \cdot \mathbf{n}
    = - \int_{\partial \Omega} (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{n}) \cdot \mathbf{v}
\end{equation}

This concludes the short derivation, because now (\ref{equ:maxwell-weak-initial-LHS})
may be rewritten as
\begin{equation}
    - \int_{\partial \Omega} (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{v}) \cdot \mathbf{n}
    + \int_{\Omega} ({\mu^{-1} \nabla \times \mathbf{u}}) \cdot (\nabla \times \mathbf{v})
\end{equation}

I would also like to demonstrate that
\begin{fancybox}{Curl product rule}
    If $\mathbf{n} \perp \mathbf{u}$ and $||\mathbf{n}|| = 1$, then
    \begin{equation}
        (\mathbf{n} \times \mathbf{u}) \times \mathbf{n} = \mathbf{u} \label{equ:double-cross-normal}
    \end{equation}
\end{fancybox}

I again resort to the old faithful Levi-Civita tensor which satisfies the
identity
\begin{equation}
    \sum_i \varepsilon_{jki} \varepsilon_{lmi} = \delta_{jl} \delta_{km} - \delta_{jm} \delta_{kl}
\end{equation}
Furthermore, I make use of the invariance of the tensor under cyclic permutation
of the indices to obtain
\begin{align}
    [(\mathbf{n} \times \mathbf{u}) \times \mathbf{n}]_k
    &= \sum_i \sum_j \varepsilon_{ijk} (\mathbf{n} \times \mathbf{u})_i n_j \notag \\ 
    &= \sum_i \sum_j \varepsilon_{ijk} \sum_l \sum_m \varepsilon_{lmi} n_l u_m n_j \notag \\ 
    &= \sum_i \sum_j \sum_l \sum_m \varepsilon_{jki} \varepsilon_{lmi} n_l u_m n_j \notag \\ 
    &= \sum_j \sum_l \sum_m (\delta_{jl} \delta_{km} - \delta_{jm} \delta_{kl}) n_l u_m n_j \notag \\
    &= \sum_j n_j u_k n_j - \sum_j n_k u_j n_j \notag \\
    &= ||\mathbf{n}||^2 u_k - (\mathbf{u} \cdot \mathbf{n}) n_k \notag \\ 
    &= u_k
\end{align}
which concludes the component-wise proof.
\end{document}