\documentclass[11pt, a4paper]{article}

\usepackage{style}

\institution{EPFL}
\project{Semester Project}
\title{Minimal Rational Interpolation for Time-Harmonic Maxwell's Equations}
\author{Fabio Matti}
\supervisor{Prof. Fabio Nobile \\ Dr. Davide Pradovera}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
    \acrfull{MRI} provides an efficient and reliable way to approximate the 
    dependence of a characteristic quantity of a model on one of its parameters.
    The focus of this report is put on the \acrfull{gMRI} algorithm and particularly
    on way to enhance its performance. This algorithm is then applied to three 
    example problems concerning the time-harmonic Maxwell's equations in the 
    frequency domain. A brief evaluation of the advantages and disadvantages of
    \acrshort{gMRI} as compared to conventional approaches for finding quantities,
    such as resonant modes, of interest for problems of this type is conducted.
\end{abstract}

%\newpage
%\printglossary[type=\acronymtype, nonumberlist]

\newpage
\tableofcontents

\newpage
\section{Introduction}
\label{sec:introduction}

A wide class of problems in physics and engineering concerns itself with the
study of the dependence of a model on one of its parameters. 
Of interest is usually a characteristic quantity that covaries with said parameter.
Unless the system allows for an analytical solution, one may usually only
find numerical solutions to the system for discrete values of the parameter.
\acrfull{MRI} offers a way to locally approximate the continuous
dependence of a model on one of its parameters. The approach has proven
effective and efficient (both memory- and computation wise) in applications
on Helmholtz-type problems \cite{greedyMRI, shortMRI}.

Central to this report are time-harmonic electromagnetic problems, whose 
parameter is the (angular) frequency. These problems are governed by
the time-harmonic Maxwell's equations. Choosing the quantity of interest
to be a vector potential, these equations reduce to a single curl-curl equation.
A justification for why a rational interpolation approach is appropriate for
this class of problems will be presented in Section \ref{subsec:motivation}.

The first few pages in this report are a short guide for finding numerical 
solutions to the time-harmonic Maxwell's equations using the \acrfull{FEM}.
These solutions are then used in the core of this report, which gives a description
of the \acrfull{gMRI} algorithm. Properties of and optimization tricks for the
\acrshort{gMRI} are shown. In the end, three applications of the method are studied and
discussed: the resonant modes of a two-dimensional resonant cavity,
the two-dimensional cavity with an imperfectly conducting boundary, and lastly
the scattering coefficients of a \acrfull{DMCWF}.

\newpage
\section{Finite element discretization of the time-harmonic Maxwell's equations}
\label{sec:maxwell}

\acrfull{MRI} requires the knowledge of the solution of the problem for multiple 
values of the model parameter that is of interested. A way of obtaining these
solutions is the \acrfull{FEM}. For that purpose, I now derive a strong formulation
for the time-harmonic Maxwell problem and subsequently convert it to its
corresponding weak formulation.

\subsection{Vector potential formulation of the time-harmonic Maxwell's equations}
\label{subsec:maxwell-potential}

% Everything smooth enough to do all manipulations...
I assume that all quantities in this section are smooth enough to perform the
necessary vector calculus manipulations.

Let $\mathbf{E}$ denote an electric field, $\mathbf{B}$ a magnetic field
strength, $\rho$ an electric charge density, and $\mathbf{j}$ an electric
current density. Maxwell's equations are stated in \citep{monk} as
\begin{align}
    \nabla \cdot (\epsilon \mathbf{E}) &= \rho \label{equ:maxwell1} \\
    \nabla \cdot \mathbf{B} &= 0 \label{equ:maxwell2} \\
    \nabla \times \mathbf{E} &= -\partial_t \mathbf{B} \label{equ:maxwell3} \\
    \nabla \times (\mu^{-1} \mathbf{B}) &= \partial_t (\epsilon \mathbf{E}) + \mathbf{j} \label{equ:maxwell4}
\end{align}
with $\varepsilon$ being the permittivity and $\mu$ the permeability (whose names 
let alone their values I always tend to forget).

% Non-conducting material, else => j = sigma*E + J_a (Monk 21)

Equation (\ref{equ:maxwell2}) motivates the expression of the magnetic field 
$\mathbf{B} = \nabla \times \mathbf{u}$ in terms of a vector-valued function
$\mathbf{u}$, the vector potential (in literature commonly denoted with
$\mathbf{A}$). Similarly, (\ref{equ:maxwell3}) suggests
rewriting the electric field $\mathbf{E} = - \nabla \phi - \partial_t \mathbf{u}$
using a scalar function $\phi$, referred to as the scalar potential.

The physical quantities $\mathbf{E}$ and $\mathbf{B}$ remain unchanged 
if we transform $\mathbf{u} \to \mathbf{u}' = \mathbf{u} + \nabla \psi$ or
$\phi \to \phi' = \phi - \partial_t \psi$ for arbitrary functions $\psi$.
A convenient choice of $\psi$ is suggested in \citep{gauge-transformation} to be
\begin{equation}
    \psi = \int_0^t \phi dt' \label{equ:gauge}
\end{equation}
which transforms $\phi \to \phi' = 0$ and $\mathbf{u} \to \mathbf{u}' = \mathbf{u}
+ \nabla \int_0^t \phi dt'$. Thus, the expressions for the electrical and
magnetic field become
\begin{align}
    \mathbf{E} &= -\partial_t \mathbf{u} \label{equ:electricfield} \\
    \mathbf{B} &= \nabla \times \mathbf{u} \label{equ:magneticfield}
\end{align}
where I have subtly renamed the variable $\mathbf{u}'$ to $\mathbf{u}$ for simplicity.

Plugging the identities (\ref{equ:electricfield}) and (\ref{equ:magneticfield})
into (\ref{equ:maxwell4}) yields 
\begin{equation}
    \nabla \times (\mu^{-1} \nabla \times \mathbf{u}) = - \epsilon \partial_t^2 \mathbf{u} + \mathbf{j} \label{equ:maxwell-potential}
\end{equation}

For the rest of this report, I restrict myself to vector potentials $\mathbf{u}$
that exhibit a harmonic dependence on time $t$, i.e. may be factorized into
a term solely depending on the position $\mathbf{x}$ and a complex exponential
depending on time
\begin{equation}
    \mathbf{u}(\mathbf{x}, t) = \mathbf{u}(\mathbf{x}) \exp(i \omega t) \label{equ:time-harmonic}
\end{equation}
Substituting this expression into (\ref{equ:maxwell-potential}) and rearranging 
a little results in the
\begin{fancybox}{Time-harmonic potential equation}
    \begin{equation}
     \nabla \times (\mu^{-1} \nabla \times \mathbf{u}) - \epsilon \omega^2 \mathbf{u} = \mathbf{j} \label{equ:maxwell-timeharmonic}
    \end{equation}
\end{fancybox}

\subsection{Weak formulation for the time-harmonic potential equation}
\label{subsec:maxwell-weak}

Equation (\ref{equ:maxwell-timeharmonic}) may be multiplied by a vector-valued
function $\mathbf{v} \in H_{\textrm{curl}}(\Omega)$, where
\begin{equation}
    H_{\textrm{curl}}(\Omega) = \{\mathbf{u} : \Omega \to \mathbb{C},~\text{such that}~\mathbf{u}\in L_2(\mathbb{C})^3, \nabla \times \mathbf{u} \in L_2(\mathbb{C})^3\} \label{equ:h-curl}
\end{equation}
and then integrated over the whole computational domain $\Omega$ to obtain 
\begin{equation}
    \int_{\Omega} (\nabla \times ({\mu^{-1} \nabla \times \mathbf{u}})) \cdot \mathbf{v}
    - \omega^2 \int_{\Omega} \epsilon \mathbf{u} \cdot \mathbf{v} = \int_{\Omega} \mathbf{j} \cdot \mathbf{v} \label{equ:maxwell-weak-initial}
\end{equation}
This may further be simplified (\ref{equ:maxwell-weak-initial}) to (I allow myself
to spare you the details of this computation, but put a proper derivation
in an appendix at the end of the report):
\begin{fancybox}{Weak formulation of the time-harmonic potential equation}
    \begin{equation}
        \int_{\Omega} ({\mu^{-1} \nabla \times \mathbf{u}}) \cdot (\nabla \times \mathbf{v})
        - \omega^2 \int_{\Omega} \epsilon \mathbf{u} \cdot \mathbf{v} 
        = \int_{\Omega} \mathbf{j} \cdot \mathbf{v}
        + \int_{\partial \Omega} \underbrace{(({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{n})}_{= \mathbf{g}} \cdot \mathbf{v}
        \label{equ:maxwell-weak}
    \end{equation}
\end{fancybox}
where $\mathbf{n}$ denotes the surface normal to the boundary $\partial \Omega$
of the computational domain $\Omega$.

Boundary conditions on the electric field $\mathbf{E}$ may be most easily enforced
in a Dirichlet-type fashion through the relation (\ref{equ:electricfield}) and
the assumption (\ref{equ:time-harmonic})
\begin{equation}
    \left.\mathbf{u}\right|_{\Gamma_D} = -\frac{1}{i\omega} \left.\mathbf{E}\right|_{\Gamma_D} \label{equ:dirichlet-boundary}
\end{equation}
Those on the magnetic field $\mathbf{B}$ through a Neumann-type condition following
from (\ref{equ:magneticfield}) and again (\ref{equ:time-harmonic})
\begin{equation}
    \left.\mathbf{g}\right|_{\Gamma_N} = (\mu^{-1} \left.\mathbf{B}\right|_{\Gamma_N}) \times \mathbf{n} \label{equ:neumann-boundary}
\end{equation}

\subsection{Examples}
\label{subsec:examples}

I will now specialize and simplify this weak formulation for three different
applications which will be studied in Section \ref{sec:examples}. To show you
that these problems are intimately related problems, I refer you to Figure \ref{fig:examples}.

\begin{figure}[h]
    \centering
    \input{figures/simple_examples.tex}
    \caption{Schematic visualization of the most trivial case for each of the
    boundary configurations that will be analyzed in Section \ref{sec:examples}.
    The perfectly conducting boundaries are drawn in black, while the imperfectly
    conducting boundary appears dashed. Inlets and exits are left unmarked.}
    \label{fig:examples}
\end{figure}

\subsubsection{Two-dimensional resonant cavity}
\label{subsubsec:cavity}

I refer to a resonant cavity as a region $\Omega$ enclosed by a boundary $\partial \Omega$.
The boundary can be subdivided into one (or more) inlets $\Gamma_N$ and a perfect
conducting wall $\Gamma_D = \partial \Omega \setminus \Gamma_N$
(see Figure \ref{fig:2d-cavity} for an abstract visualization of such a cavity).

\begin{figure}[h]
    \centering
    \input{figures/2d_cavity.tex}
    \caption{An abstract example of a two-dimensional resonant cavity enclosing
    a domain $\Omega$ with a perfectly conducting boundary $\Gamma_D$ and
    featuring a single inlet $\Gamma_N$.}
    \label{fig:2d-cavity}
\end{figure}

Suppose the current density $\mathbf{j} \equiv 0$ and orient the coordinate
system in such a way that $\mathbf{u} = u_z \mathbf{e}_z$ and 
$\mathbf{v} = v_z \mathbf{e}_z$. Consequently, the scalar product of the two 
curls in Equation (\ref{equ:equ:maxwell-weak}) simplifies to the scalar product 
of two gradients:
\begin{equation}
    (\mu^{-1} \nabla \times \mathbf{u}) \cdot (\nabla \times \mathbf{v})
    = (\mu^{-1} \nabla u_z) \cdot (\nabla v_z)
\end{equation}
Denote by $g_z$ the component of $\mathbf{g}$ in the $z$-direction along the
inlet $\Gamma_N$. These simplifications allow the conversion of 
(\ref{equ:maxwell-weak}) into the weak formulation for a two-dimensional
resonant cavity
\begin{equation}
    \int_{\Omega} (\mu^{-1} \nabla u_z) \cdot (\nabla v_z)
    - \omega^2 \int_{\Omega} \epsilon u_z v_z
    = \int_{\partial \Omega} g_z v_z \label{equ:maxwell-weak-resonant-cavity}
\end{equation}

% Boundary conditions Dirichlet and Neumann (from Monk)
Now, let $\mathbf{E}$ and $\mathbf{B}$ refer to the electric and magnetic fields inside
the cavity. For now, I distinguish between two types of boundaries:

For the perfectly conducting boundary $\Gamma_D$, treated in \citep{monk}, it holds that
\begin{equation}
    \mathbf{n} \times \mathbf{E} = 0,~~\text{on}~\Gamma_D \label{equ:perfect-conductor-boundary}
\end{equation}
For the boundaries in a two-dimensional resonant cavity (see Figure 
\ref{fig:2d-cavity}), this only holds true if $E_z = 0$, which translates
to the Dirichlet boundary condition $\left.\mathbf{u}\right|_{\Gamma_D} = 0$
in light of (\ref{equ:dirichlet-boundary}).

For the inlet, it is easiest to enforce the boundary condition through the
magnetic field $\mathbf{B}$ in exactly the way proposed in
(\ref{equ:neumann-boundary}) (assuming $\mathbf{n} = -\mathbf{e}_x$ as
will always be the case in Section \ref{sec:examples}, cf. Figure \ref{fig:rectangular_cavity}):
\begin{equation}
    g_z = (({\mu^{-1} \mathbf{B}}) \times (-\mathbf{e}_x))_z = \mu^{-1} B_x,~~\text{on}~\Gamma_N
\end{equation}

\subsubsection{Imperfect conductor}
\label{subsubsec:impedance}

% Additionally impedance boundary condition from Monk
To simulate an imperfect boundary $\Gamma_I$, also called impedance boundary in literature, 
\cite{monk} suggests to replace the integrand $\mathbf{g}$ that appeared in 
(\ref{equ:maxwell-weak}) with
\begin{equation}
    \mathbf{g} = (\mu^{-1} \nabla \times \mathbf{u}) \times \mathbf{n}
    = i \omega \lambda (\mathbf{n} \times \mathbf{u}) \times \mathbf{n}~~\text{on}~\Gamma_D
\end{equation}
with a parameter $\lambda>0$ I will henceforth refer to as the impedance.
Supposing that $\mathbf{u} = u_z \mathbf{e}_z$ and only treating a
two-dimensional domain, this condition simplifies to (using the fact that $\mathbf{n} \perp \mathbf{u}$
and $||\mathbf{n}|| = 1$, so $(\mathbf{n} \times \mathbf{u}) \times \mathbf{n} = \mathbf{u}$,
as is demonstrated in the appendix at the end of this report)
\begin{equation}
    g_z = i \omega \lambda u_z~~\text{on}~\Gamma_D
\end{equation}
Therefore, an impedance boundary can be treated in almost the same way as a
Neumann boundary in the two-dimensional weak formulation (\ref{equ:maxwell-weak-resonant-cavity})
of a resonant cavity.

\subsubsection{Waveguide}
\label{subsubsec:waveguide}

% Just j=0 and 3d, need to discuss boundary conditions
Going back to (\ref{equ:maxwell-weak}) and this time staying in three dimensions,
we again assume no electric current density $\mathbf{j} \equiv 0$ is present.
I suppose that the inlet is located at a constant $x$-value,
such that the surface normal to this inlet is $-\mathbf{e}_x$. Conveniently, the example 
in Section \ref{subsec:examples-dmcwf} happens to be set up in just this way. For an incoming
magnetic field at the inlet $\Gamma_i$ with $\left.\mathbf{B}\right|_{\Gamma_i} = B_0 \mathbf{e}_y$,
we see from (\ref{equ:neumann-boundary}) that this may be modelled by setting
$\left.\mathbf{g}\right|_{\Gamma_i} = - \mu^{-1} B_0 \mathbf{e}_z$.
At the \enquote{exit} $\Gamma_e$, we set $\left.\mathbf{g}\right|_{\Gamma_e} = \boldsymbol{0}$.

\newpage
\section{Finite element approximation with FEniCS}
\label{sec:fem}

Based on the weak formulation corresponding to the time-harmonic potential equation
(\ref{equ:maxwell-weak}), the \acrfull{FEM} can be used to approximate solutions 
to Equation (\ref{equ:maxwell-timeharmonic}).

\subsection{The Galerkin method}
\label{subsec:fem-theory}

% Theory
It is readily seen that the weak formulation (\ref{equ:maxwell-weak}) assumes the shape
\begin{equation}
    \text{Find}~\mathbf{u} \in H_{\textrm{curl}}(\Omega),~\text{such that}~a_{\omega}(\mathbf{u}, \mathbf{v}) = L(\mathbf{v}), ~\forall \mathbf{v} \in H_{\textrm{curl}}(\Omega)
\end{equation}
with the bilinear form 
\begin{equation}
    a_{\omega}(\mathbf{u}, \mathbf{v}) = \underbrace{\int_{\Omega} (\mu^{-1} \nabla \times \mathbf{u}) \cdot (\nabla \times \mathbf{v})}_{K(\mathbf{u}, \mathbf{v})}
    - \omega^2 \underbrace{\int_{\Omega} \epsilon \mathbf{u} \cdot \mathbf{v}}_{M(\mathbf{u}, \mathbf{v})} \label{equ:bilinear-form}
\end{equation}
and the linear form 
\begin{equation}
    L(\mathbf{u}) = \int_{\Omega} \mathbf{j} \cdot \mathbf{v} + \int_{\partial \Omega} \mathbf{g} \cdot \mathbf{v} \label{equ:linear-form}
\end{equation}
and the appropriate Hilbert space $H_{\textrm{curl}}(\Omega)$ defined in (\ref{equ:h-curl}).

A sequence of appropriate 
finite dimensional spaces $H_{\textrm{curl}, h}(\Omega)$ is introduced, and the
Galerkin problem is then formulated as (see \cite{numapproxPDEs} for details)
\begin{fancybox}{Galerkin problem for the time-harmonic potential equation}
    \begin{equation}
        \text{Find}~\mathbf{u}_h \in H_{\textrm{curl},h}(\Omega),~\text{such that}~a_{\omega}(\mathbf{u}_h, \mathbf{v}_h) = L(\mathbf{v}_h), ~\forall \mathbf{v} \in H_{\textrm{curl}, h}(\Omega) \label{equ:galerkin-problem}
    \end{equation}
\end{fancybox}
One class of finite elements, the Nédélec elements of the first
kind, are particularly well suited for discretizing curl-problems of the type
we have derived in Section \ref{sec:maxwell} (see \cite{monk}).

I refer to the \acrshort{FEM} matrix representations in the vertex basis of the forms
$K(\mathbf{u}, \mathbf{v})$ and $M(\mathbf{u}, \mathbf{v})$ as the
stiffness matrix $\mathbf{\underline{K}}$ and mass matrix $\mathbf{\underline{M}}$.

\subsection{Numerical approximation of \acrshort{PDE}s using FEniCS}
\label{subsec:fem-demo}

% Demonstration
FEniCS\footnote{\url{https://fenicsproject.org/}} bundles a collection of Python
modules designed to automate solving a \acrfull{PDE}.
Inspired by the demonstrations encountered in \cite{fenics}, I will now guide you
through a simple example, relevant to the context of this report, in order to
show how the process of obtaining
approximate solutions to \acrshort{PDE}s with FEniCS.

Consider the time-harmonic potential equation (\ref{equ:maxwell-timeharmonic})
with the computational domain $\Omega$ being a cubic cavity with an inlet $\Gamma_N$
on one of its sides, but all other boundaries being perfect conductors.
Set $\mu = \epsilon = 1$ and $\mathbf{j} = 0$ for simplicity.

The \texttt{fenics} package is imported along with \texttt{numpy} and
\texttt{matplotlib.pyplot} for array manipulation and visualization respectively.
\lstinputlisting[firstnumber=1, firstline=2, lastline=3]{code/fenics_example.py}

A mesh for the cubic cavity $\Omega$ is generated by dividing the cube into a
$10\times10\times10$ grid, whose cells are again subdivided into tetrahedrons.
\lstinputlisting[firstnumber=5, firstline=6, lastline=7]{code/fenics_example.py}

Our function space $H_{\textrm{curl},h}(\Omega)$ is composed using piecewise
linear Nédélec elements of the first kind.
\lstinputlisting[firstnumber=9, firstline=10, lastline=10]{code/fenics_example.py}

The inlet is introduced at $x = 0$.
\lstinputlisting[firstnumber=12, firstline=13, lastline=15]{code/fenics_example.py}

All other boundaries are perfectly conducting walls.
\lstinputlisting[firstnumber=17, firstline=18, lastline=20]{code/fenics_example.py}

A mesh function is used to identify the different boundaries. It evaluates to
0, if a vertex is not on any boundary; 1 if the vertex is a the inlet; and 2 if
the vertex sits on a perfectly conducting boundary.
\lstinputlisting[firstnumber=22, firstline=23, lastline=26]{code/fenics_example.py}

For Nédélec elements of the first kind, (\ref{equ:perfect-conductor-boundary})
is enforced through
\lstinputlisting[firstnumber=28, firstline=29, lastline=30]{code/fenics_example.py}

Let $\mathbf{g} = \mathbf{e}_z$ in (\ref{equ:neumann-boundary}), which corresponds
to a magnetic field $\mu^{-1} \mathbf{B} = \mathbf{e}_y$.
\lstinputlisting[firstnumber=32, firstline=33, lastline=34]{code/fenics_example.py}

Trial and test functions for the function space $H_{\mathrm{curl},h}(\Omega)$ are instantiated.
\lstinputlisting[firstnumber=36, firstline=37, lastline=38]{code/fenics_example.py}

The linear form (\ref{equ:linear-form}) is assembled.
\lstinputlisting[firstnumber=40, firstline=41, lastline=41]{code/fenics_example.py}

The stiffness matrix (i.e. the first term in the bilinear form (\ref{equ:bilinear-form}))
is assembled, and the Dirichlet boundary conditions are applied.
\lstinputlisting[firstnumber=43, firstline=44, lastline=45]{code/fenics_example.py}

The mass matrix (i.e. the second term in the bilinear form (\ref{equ:bilinear-form}))
is assembled, and the Dirichlet boundary conditions are accounted for by setting
all rows and columns corresponding to degrees of freedom on the perfectly conducting
boundary to zero.
\lstinputlisting[firstnumber=47, firstline=48, lastline=49]{code/fenics_example.py}

A function to compute an approximation of the $L_2(\Omega)$-norm of a solution
to the system can be created. Notice how I can reuse the mass matrix
$\mathbf{\underline{M}}$ for this purpose only due to the fact that
$\epsilon = 1$ was taken.
\lstinputlisting[firstnumber=51, firstline=52, lastline=54]{code/fenics_example.py}

Finally, for 200 uniformly spaced frequencies $\omega \in [6.2, 6.8]$, the 
approximate solution to the cubic cavity at each of these frequencies is
computed and its $L_2(\Omega)$-norm memorized for later.
\lstinputlisting[firstnumber=56, firstline=57, lastline=62]{code/fenics_example.py}

What results is an approximation of the frequency response in the $L_2(\Omega)$-norm
for the cubic cavity (see Figure \ref{fig:fenics-demonstration}). 
\begin{figure}[h]
    \centering
    \input{plots/fenics_demonstration.pgf}
    \caption{Approximate frequency response in the $L_2(\Omega)$-norm of a cubic cavity with
    one face acting as an inlet and all others as perfectly conducting boundaries.
    At resonant frequencies, the $L_2(\Omega)$-norm theoretically tends to infinity.
    Numerically, they appear as finite peaks in the frequency response.}
    \label{fig:fenics-demonstration}
\end{figure}

\newpage
\section{Minimal rational interpolation for the time-harmonic Maxwell's equations}
\label{sec:mri}

% General idea 
Let $\mathbf{u} : \mathbb{C} \to \mathbb{C}^3$ or $\mathbb{C}^2$. Given \enquote{snapshots} of the
function $\mathbf{u}(\omega_j)$ at $\omega_j$ for $j \in \{1, \dots, S\}$, the
goal is to find a surrogate that locally (i.e. near $\omega_1, \dots, \omega_S$)
satisfies
\begin{equation}
    \mathbf{\tilde{u}}(\omega) \approx \mathbf{u}(\omega)
\end{equation}
This may be achieved using the \acrfull{MRI} technique, which I will motivate,
discuss, and extend in the following.

\subsection{Motivation}
\label{subsec:motivation}

In the most simple case (dropping all constants), equations of the type
(\ref{equ:maxwell-timeharmonic}) take the form
\begin{equation}
    \nabla \times (\nabla \times \mathbf{u}) - \omega^2 \mathbf{u} = \mathbf{j}
    \label{equ:maxwell-timeharmonic-simple}
\end{equation}
Writing the double-curl operator in terms of a matrix $\mathbf{\underline{A}}$
allows for an expression of the solution $\mathbf{u}$ to (\ref{equ:maxwell-timeharmonic-simple})
as
\begin{equation}
    \mathbf{u} = (\mathbf{\underline{A}} - \omega^2)^{-1} \mathbf{j}
\end{equation}
The eigenvalue decomposition $\mathbf{\underline{A}} = \mathbf{\underline{V}}
~ \boldsymbol{\underline{\Lambda}} ~ \mathbf{\underline{V}}^H$
leads to a similar form as the one proposed in \cite{helmholtz-motivation}
\begin{equation}
    \mathbf{u} = \mathbf{\underline{V}} (\boldsymbol{\underline{\Lambda}} - \omega^2 \boldsymbol{\underline{1}})^{-1} \mathbf{\underline{V}}^H \mathbf{j} 
    = \sum_i \frac{\mathbf{v}_i \mathbf{v}_i^H \mathbf{j}}{\lambda_i - \omega^2} \label{equ:motivation}
    %= \sum_i \frac{\mathbf{r}_i}{\lambda_i - \omega^2} \label{equ:motivation}
\end{equation}
This follows from the fact that $\boldsymbol{\underline{\Lambda}}$ is diagonal,
hence also $(\boldsymbol{\underline{\Lambda}} - \omega^2 \boldsymbol{\underline{1}})^{-1}$.
Here, the diagonal elements of $\boldsymbol{\underline{\Lambda}}$ are denoted with 
$\lambda_i$ (the eigenvalues of $\mathbf{\underline{A}}$) and the columns of
$\mathbf{\underline{V}}$ with $\mathbf{v}_i$ (the eigenvectors of $\mathbf{\underline{A}}$).

With the expression of the solution $\mathbf{u}$ in terms of a rational polynomial
function (see (\ref{equ:motivation})), we can motivate why rational interpolation
is a valid approach for approximating $\mathbf{u}$. Some alternatives such as polynomial
interpolation are not as capable to model the singularities at the resonant
frequencies $\omega^2 = \lambda_i$.

Consequently, the goal is to find rational surrogates of the form
\begin{equation}
    \mathbf{\tilde{u}}(\omega) = \frac{\mathbf{P}(\omega)}{Q(\omega)}
\end{equation}
with
\begin{equation}
    \mathbf{P}(\omega) = \sum_i \frac{\mathbf{p}_i}{\omega - \omega_i}
\end{equation}
and
\begin{equation}
    Q(\omega) = \sum_i \frac{q_i}{\omega - \omega_i} \label{equ:surrogate-denominator}
\end{equation}
in the barycentric representation.

\subsection{Minimal rational interpolation}
\label{subsec:MRI}

In the following, I denote with
\begin{equation}
    \langle u, v \rangle_M = \mathbf{u}^H \mathbf{\underline{M}} \mathbf{v} \approx \int_{\Omega} u v \label{equ:matrix-inner-product}
\end{equation}
the finite element approximation of the inner product in $L_2(\Omega)$.
$\mathbf{u}$ and $\mathbf{v}$ are the vectors collecting the vertex values for
all degrees of freedom, while $\mathbf{\underline{M}}$ is the representation matrix
of the inner product in the vertex basis. Similarly, let
\begin{equation}
    ||u||_M = \sqrt{\langle u, u \rangle}_M \approx ||u||_{L_2(\Omega)} \label{equ:matrix-norm}
\end{equation}

% Algorithm (last column SVD is definition of MRI)
For completeness, I state the strategy for numerically computing the \acrfull{MRI} 
for a collection of snapshots sampled from the target $\mathbf{u}$ \citep{greedyMRI}
in Algorithm \ref{alg:MRI}. The heart of the algorithm consists in computing the
\acrfull{SVD} of the so-called Gramian matrix, and using the last
left-singular vector to build the surrogate.

\begin{algorithm}
    \caption{Minimal rational interpolation} \label{alg:MRI}
    \input{algorithms/MRI.tex}
\end{algorithm}

\subsection{Greedy minimal rational interpolation}
\label{subsec:gMRI}

A question that arises from the previous section is what the ideal choice of
support points $\omega_1, \dots, \omega_S$ is: How many support points are
required to achieve a good enough approximation and how should the supports
be distributed when given a target domain. The \acrfull{gMRI} algorithm 
\citep{shortMRI} tackles both questions simultaneously.

In brief, the algorithm starts with a set of candidate support points
$\Omega_{\mathrm{test}} = \{\omega_i\}_{i=1}^M$, for which we can guarantee
to find an approximate solution to (\ref{equ:galerkin-problem}). 
From the $\Omega_{\mathrm{test}}$ a subset is chosen (usually the smallest and
largest element), and (\ref{equ:galerkin-problem}) is solved for these two initial
supports. Using these solutions, a rational surrogate is built with
\acrshort{MRI} (Algorithm \ref{alg:MRI}). Motivated by the expression for the
upper bound on the residual norm demonstrated in \cite{theoryMRI}, new support
points are chosen as the minimizers of the denominator polynomial $Q(\omega)$
and added to the set of supports. Support points are iteratively added until
the relative error norm drops below a certain tolerance.

The \acrshort{gMRI} algorithm can be found in Algorithm \ref{alg:gMRI}.

\begin{algorithm}
    \caption{Greedy minimal rational interpolation} \label{alg:gMRI}
    \input{algorithms/gMRI.tex}
\end{algorithm}

\subsection{Properties of rational interpolants in barycentric coordinates}
\label{subsec:properties}

% Interpolation property (in barycentric expansion, l'Hôpital whatever)
The rational surrogate $\mathbf{\tilde{u}}$ obtained with Algorithm \ref{alg:MRI}
can be rewritten as
\begin{equation}
    \mathbf{\tilde{u}}(\omega)
    = \sum_{j=1}^S \prod_{\substack{i=0 \\ i \neq j}}^S (\omega - \omega_i) q_j \mathbf{u}(\omega_j)
    / \sum_{j=1}^S \prod_{\substack{i=0 \\ i \neq j}}^S (\omega - \omega_i) q_j
\end{equation}
Hence, if the rational surrogate $\mathbf{\tilde{u}}$ is evaluated at one of the
interpolation nodes $\omega_i$, the snapshot $\mathbf{u}(\omega_i)$ supplied to 
the \acrshort{MRI} algorithm is recovered. This shows that the rational surrogate
satisfies the interpolation property.

\subsection{Finding roots of rational functions}
\label{subsec:roots}
% Rational root finding 

If the rational surrogate $\mathbf{\tilde{u}}$ is evaluated in a zero
$\omega^\ast$ of the denominator $Q(\omega^\ast) = 0$, we observe a pole,
provided $P(\omega^\ast)$ does not also vanish in that frequency.
$\omega^\ast$ is referred to as a resonant frequency.

In order to find the approximate resonant frequencies of a system,
we simply need to perform the following steps:

\begin{enumerate}
    \item Compute the rational surrogate using \acrshort{MRI} or \acrshort{gMRI}.
    \item Determine the zeros of the denominator $Q(\omega)$ of the surrogate
\end{enumerate}

The first step was already elaborated upon in Sections \ref{subsec:MRI} and \ref{subsec:gMRI}.
Finding the zeros of a rational function of the form (\ref{equ:surrogate-denominator})
can be elegantly converted to an eigenvalue problem \citep{klein}:

Define
\begin{equation}
    v_i = (\omega - \omega_i)^{-1}
\end{equation}
We want to find $\omega$, such that
\begin{equation}
    0 = Q(\omega) = \sum_{i=1}^S q_i v_i(\omega)
\end{equation}
This can be equivalently expressed as the generalized eigenvalue problem
\begin{equation}
    \mathbf{\underline{A}} \mathbf{u} = \omega \mathbf{\underline{B}} \mathbf{u} \label{equ:eigenvalue-problem}
\end{equation}
with
\begin{equation}
    \mathbf{\underline{A}} = \begin{pmatrix}
        0 & q_1 & q_2 & \dots & q_S \\
        1 & \omega_1 & & & \\
        1 & & \omega_2 & & \\ 
        \vdots & & & \ddots & \\ 
        1 & & & & \omega_S
    \end{pmatrix} ~~\text{and}~~
    \mathbf{\underline{B}} = \begin{pmatrix}
        0 & & & & \\
         & 1 & & & \\
         & & 1 & & \\ 
        \vdots & & & \ddots & \\ 
         & & & & 1
    \end{pmatrix}\label{equ:root-finding}
\end{equation}

\subsection{Optimization tricks for greedy minimal rational interpolation}
\label{subsec:optimization}
% Optimization tweaks

There exist many ways of improving the efficiency and/or capability of the
\acrshort{gMRI} algorithm \cite{davidePHD}. In the following, I will present
a small collection of them.

\subsubsection{Additive Householder decomposition}
\label{subsubsec:householder}
% -> Householder sequential algorithm instead of full Gramian

Algorithm \ref{alg:MRI} requires the computation of the \acrfull{SVD}
of the Gramian matrix $\mathbf{\underline{G}}$ in order to build the rational
surrogate. A more efficient and better conditioned \cite{davidePHD} alternative is to compute
the QR decomposition of the snapshot matrix $\mathbf{\underline{U}} = [\mathbf{u}(\omega_1), \dots, \mathbf{u}(\omega_S)]$.
Since
\begin{equation}
    \mathbf{\underline{G}} = \mathbf{\underline{U}}^H \mathbf{\underline{M}}~\mathbf{\underline{U}} \label{equ:gramian-matrix}
\end{equation}
with the matrix $\mathbf{\underline{M}}$ representing the finite element 
inner product in $L_2(\Omega)$ in the basis of the mesh vertices.
A QR decomposition with respect to the inner product
$\langle \mathbf{u}, \mathbf{v} \rangle_M = \mathbf{u}^H \mathbf{\underline{M}} \mathbf{v}$
yields $\mathbf{\underline{U}} = \mathbf{\underline{Q}}~\mathbf{\underline{R}}$
with $\mathbf{\underline{Q}}^H \mathbf{\underline{M}}~\mathbf{\underline{Q}} = \boldsymbol{\underline{1}}$.
When plugging this into (\ref{equ:gramian-matrix}) one sees
\begin{equation}
    \mathbf{\underline{G}} = (\mathbf{\underline{Q}}~\mathbf{\underline{R}})^H \mathbf{\underline{M}} 
    (\mathbf{\underline{Q}}~\mathbf{\underline{R}}) = \mathbf{\underline{R}}^H~\mathbf{\underline{R}}
    \label{equ:gramian-QR}
\end{equation}

Let the \acrshort{SVD} of $\mathbf{\underline{R}}$ be 
\begin{equation}
    \mathbf{\underline{R}} = \mathbf{\underline{W}}~\mathbf{\underline{S}}~\mathbf{\underline{V}}^H \label{equ:qr-decomposition}
\end{equation}
Inserting this into (\ref{equ:gramian-QR}) results in
\begin{equation}
    \mathbf{\underline{G}} = (\mathbf{\underline{W}}~\mathbf{\underline{S}}~\mathbf{\underline{V}}^H)^H \mathbf{\underline{W}}~\mathbf{\underline{S}}~\mathbf{\underline{V}}^H
    = \mathbf{\underline{V}}~\mathbf{\underline{S}}^2\mathbf{\underline{V}}^H
    \label{equ:gramian-SVD}
\end{equation}
which coincides with the \acrshort{SVD} of the Gramian matrix $\mathbf{\underline{G}}$
if we take the square root of the singular values. Since for \acrshort{MRI} only
really the last left singular vector in $\mathbf{\underline{V}}$ is of interest,
computing $\mathbf{\underline{G}}$ explicitly may be avoided.

There is one additional benefit to taking the route via the \acrshort{SVD} of
$\mathbf{\underline{R}}$ instead of $\mathbf{\underline{G}}$
for building the surrogate: When extending the snapshot matrix by an additional
snapshot $\mathbf{u}(\omega_{S+1})$, the resulting triangular matrix $\mathbf{\underline{R}}^{(S+1)}$
from a QR decomposition on this extended snapshot matrix only differs from the 
(usually already computed) matrix $\mathbf{\underline{R}}^{(S)}$ only in the last column.
Thus, it is possible to reuse many results obtained in a previous iterations of
the \acrshort{gMRI} algorithm and therefore significantly increase computational
efficiency.

I developed such an additive QR decomposition in Algorithm \ref{alg:householder},
which results from an adaption of the Householder triangularization algorithm
found in \citep{householder}. In essence, this algorithm takes the triangular
matrix $\mathbf{\underline{R}}$, orthonormal matrix $\mathbf{\underline{E}}$,
and Householder matrix $\mathbf{\underline{V}}$ and extends each of them according
to the additional snapshots supplied to the algorithm.

\begin{algorithm}
    \caption{Additive Householder triangularization} \label{alg:householder}
    \input{algorithms/householder.tex}
\end{algorithm}

% -> Twice is enough?

\subsubsection{Stability of singular value decomposition}
\label{subsubsec:svd}
% -> Check stability of build with SVDs (maybe also mention G / R difference)
The stability of the build of the rational surrogate using \acrshort{MRI}
can be checked by analyzing the singular values $\sigma_1, \dots, \sigma_S$ 
obtained from performing the \acrshort{SVD}. Assume these values to be
ordered in descending order, which the Python package
\texttt{numpy} automatically does when computing the \acrshort{SVD} of a matrix. 
The conditioning of the problem may be measured with the relative
spectral gap \cite{davidePHD}
\begin{equation}
    \frac{\sigma_{S-1} - \sigma_S}{\sigma_1 - \sigma_S} \label{equ:spectral-gap}
\end{equation}
Usually, values of above $10^{13}$ indicate that the rational surrogate could not
be built in a stable way and in my implementations the user is warned.

\subsubsection{Alternative representations of the surrogate}
\label{subsubsec:u-ring}
% -> Model order reduction techniques (u_ring, error computation, ...)
Denote with $\mathbf{\underline{U}} = [\mathbf{u}(\omega_1), \dots, \mathbf{u}(\omega_S)]$
the snapshot matrix. Let 
\begin{equation}
    \accentset{\circ}{\mathbf{u}}(\omega) = \sum_{j=1}^S \frac{q_j \mathbf{e}_j}{\omega - \omega_j}
    / \sum_{j=1}^S \frac{q_j}{\omega - \omega_j} \label{equ:u-ring}
\end{equation}
with the canonical basis vectors $\{ \mathbf{e}_j \}_j$, and denote
$\accentset{\circ}{\mathbf{\underline{U}}} = [\accentset{\circ}{\mathbf{u}}(\omega_1), \dots, \accentset{\circ}{\mathbf{u}}(\omega_S)]$
Inspecting the rational surrogate (defined in Algorithm \ref{alg:MRI}) closely,
one can see that the rational surrogate can be recovered from $\accentset{\circ}{\mathbf{u}}$
via
\begin{equation}
    \mathbf{\tilde{u}}(\omega) = \mathbf{\underline{U}} \accentset{\circ}{\mathbf{u}}(\omega)
\end{equation}
Therefore, provided we know the snapshot matrix, a rational surrogate is
fully characterized by just $S$ numbers $\{q_1, \dots, q_S\}$
and the locations of the interpolation nodes $\{\omega_1, \dots, \omega_S\}$.

Additionally, let
\begin{equation}
    \mathbf{\hat{u}}(\omega) = \sum_{j=1}^S \frac{q_j \mathbf{r}_j}{\omega - \omega_j}
    / \sum_{j=1}^S \frac{q_j}{\omega - \omega_j} \label{equ:u-ring}
\end{equation}
with $\mathbf{r}_j$ being the $j$-th column in the triangular matrix
$\mathbf{\underline{R}}$ stemming from the QR decomposition of the snapshot
matrix $\mathbf{\underline{U}} = \mathbf{\underline{Q}} ~ \mathbf{\underline{R}}$.
Then, the original rational surrogate can again be recovered via
\begin{equation}
    \mathbf{\tilde{u}}(\omega) = \mathbf{\underline{Q}} \mathbf{\hat{u}}(\omega)
\end{equation}
$\mathbf{\hat{u}}(\omega)$ provides us with a simplified alternative to the
computation of the relative error which is used as a stopping criterion in
\acrshort{gMRI} (Algorithm \ref{alg:gMRI}):

First, one may use the $\mathbf{\underline{M}}$-orthonormality of $\mathbf{\underline{Q}}$
to get
\begin{align}
    ||\mathbf{u}_{t+1}(\omega_{t+1}) - \mathbf{\tilde{u}}_{t}(\omega_{t+1})||_M^2
    &= ||\mathbf{\underline{Q}}^{(t+1)} \mathbf{r}_{t+1} - \mathbf{\underline{Q}}^{(t+1)}\mathbf{\hat{u}}_{t}'(\omega_{t+1})||_M^2 \notag \\
    %&= (\mathbf{r}_{t+1} - \mathbf{\hat{u}}_{t}'(\omega_{t+1}))^H (\mathbf{\underline{Q}}^{(t+1)})^H \mathbf{\underline{M}} \mathbf{\underline{Q}}^{(t+1)} (\mathbf{r}_{t+1} - \mathbf{\hat{u}}_{t}'(\omega_{t+1})) \notag \\
    &= ||\mathbf{r}_{t+1} - \mathbf{\hat{u}}_{t}'(\omega_{t+1})||^2
\end{align}
with the short hand $\mathbf{\hat{u}}_{t}' = [\mathbf{\hat{u}}_{t}^T, 0]^T$
and where $\mathbf{r}_{t+1}$ is the last column in $\mathbf{\underline{R}}^{(t+1)}$,
he triangular matrix from the $(t+1)$-th step in the additive Housholder decomposition
(Algorithm \ref{alg:householder}). $||.||$ is the Euclidean norm.

Additionally, one may similarly approximate
\begin{equation}
    ||\mathbf{u}(\omega)||_M^2 \approx ||\mathbf{\tilde{u}}(\omega)||_M^2
    = ||\mathbf{\underline{U}} \accentset{\circ}{\mathbf{u}}(\omega)||_M^2
    = \accentset{\circ}{\mathbf{u}}(\omega)^H \underbrace{\mathbf{\underline{U}}^H \mathbf{\underline{M}} \mathbf{\underline{U}}}_{= \mathbf{\underline{G}} = \mathbf{\underline{R}}^H \mathbf{\underline{R}}} \accentset{\circ}{\mathbf{u}}(\omega)
    = \mathbf{\hat{u}}(\omega)^H \mathbf{\hat{u}}(\omega)
    = ||\mathbf{\hat{u}}(\omega)||^2
\end{equation}
Thus, the relative error norm can be approximated with only Euclidean norms.

\newpage
\section{Examples}
\label{sec:examples}

The goal is now to apply the techniques introduced in the previous sections
to three examples (see Figure \ref{fig:examples} to get an idea about the
difference between these examples).

\subsection{Two-dimensional rectangular resonant cavity}
\label{subsec:examples-rectangularcavity}

Based on the theoretical considerations from Section \ref{subsec:examples-rectangularcavity},
a rectangular resonant cavity with dimensions $L_x=5$ and $L_y=1$ (see Figure 
\ref{fig:rectangular_cavity}) is studied.
\begin{figure}[h]
    \centering
    \input{figures/rectangular_cavity.tex}
    \caption{The rectangular resonant cavity is a medium $\Omega$ enclosed
    by a perfectly conducting boundary $\Gamma_D$ and an inlet $\Gamma_N$
    chosen to coincide with the rectangle's edge at $x=0$ for the experiments in this
    section.}
    \label{fig:rectangular_cavity}
\end{figure}

For simplicity, I set $\epsilon=\mu=1$. A uniform grid with 101 subdivisions in
the $x$- and 21 in the $y$-direction whose cells are again subdivided by their
diagonals was used to generate a mesh that allows for 4365 degrees of freedom.
The system is forced from the inlet at $x=0$ with $g_z(y) = sin(\pi y / L_y)$.

% Exploratory plots
\subsubsection{Exploration of the problem}
\label{subsubsec:exploration}

To give the reader an impression of what the solution $u_z(x, y)$ to this problem
looks like, I plot the \acrshort{FEM}-solution at the first and fifth resonant
frequency in Figures \ref{fig:rectangular-cavity-mode1} and \ref{fig:rectangular-cavity-mode5}
respectively.

\begin{figure}[ht]
    \centering
    \includegraphics{plots/rectangular_cavity_mode1.pdf}
    \caption{The solution $u_z(x, y)$ obtained with the \acrshort{FEM} at the
    first resonant frequency $\omega = 3.159$ of the cavity. Observe how at
    every perfectly conducting boundary $\Gamma_D$ (cf. Figure
    \ref{fig:rectangular_cavity}) the solution gradually goes to zero, as was imposed.}
    \label{fig:rectangular-cavity-mode1}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics{plots/rectangular_cavity_mode5.pdf}
    \caption{The solution $u_z(x, y)$ obtained with the \acrshort{FEM} at the
    fifth resonant frequency $\omega = 4.675$ of the cavity.}
    \label{fig:rectangular-cavity-mode5}
\end{figure}

% Rational interpolation demonstration
I now study the \acrshort{gMRI} of the quantity $||u_z||_M$ defined in
(\ref{equ:matrix-norm}). Algorithm \ref{alg:gMRI} is performed
with a tolerance of $\tau = 10^{-2}$. The candidate support points $\Omega_{\mathrm{test}}$
are 1000 uniformly spaced points in $\omega = [3, 5]$. The \acrshort{FEM} solution $u_z$
is computed and the \acrshort{gMRI} surrogate $\tilde{u}_z$ evaluated at all points in $\Omega_{\mathrm{test}}$,
and the $||.||_M$-norm for both is plotted in Figure \ref{fig:rectangular-cavity-norms}. 

\begin{figure}[ht]
    \centering
    \input{plots/rectangular_cavity_norms.pgf}
    \caption{$||.||_M$-norm of the \acrshort{FEM} solution $u_z$ (top) and the 
    \acrshort{gMRI} surrogate $\tilde{u}_z$ (bottom).}
    \label{fig:rectangular-cavity-norms}
\end{figure}

For the same problem, the approximation of the relative error 
in the $||.||_M$-norm of the rational surrogate $\tilde{u}_z^{(S)}$ from the
\acrshort{FEM} solution in every second iteration $S$ of the \acrshort{gMRI} algorithm
is shown in Figure \ref{fig:rectangular-cavity-errorprogression}. This time,
however, the candidate support points for the rational surrogate $\tilde{u}_z^{(S)}$
and the points at which the \acrshort{FEM}-solution and the rational surrogate
are compared are completely out of sync. Because if they coincided, the relative error
would obviously tend to zero at each of the support points chosen for building
the surrogate, which would obscure the point I want to make with this plot.

\begin{figure}[ht]
    \centering
    \input{plots/rectangular_cavity_errorprogression.pgf}
    \caption{Progression of a relative approximation error of the rational
    surrogates $\tilde{u}_z^{(S)}$ that was built using $S$ support points.
    The freshly added support points during the previous two iterations of
    \acrshort{gMRI} are shown in their corresponding color at the bottom.
    Notice how the decrease in relative error is not uniform, and wherever a
    support point is added, the error is locally decreased.}
    \label{fig:rectangular-cavity-errorprogression}
\end{figure}

\subsubsection{Numerical approximation of resonant frequencies}
\label{subsubsec:root-finding}

As already discussed in Section \ref{subsec:roots}, \acrshort{gMRI} may be used
to approximate resonant frequencies of a system. Conveniently enough, the analytical
resonant frequencies for a rectangular resonant cavity as the one currently being 
studied easy to determine due to separability and the homogeneous boundary conditions. 
\begin{equation}
    \omega_{n, m} = \pi \sqrt{\left(\frac{2n + 1}{2L_x}\right)^2 + \left(\frac{m}{L_y}\right)^2},
    ~n \in \{0, 1, \dots\}, ~m \in \{1, 2, \dots \} \label{equ:analytical-eigenmodes}
\end{equation}
Conventionally, resonant frequencies would be determined by solving the generalized
(hermitian) eigenvalue problem
\begin{equation}
    \mathbf{\underline{K}} \mathbf{u} = \omega^2 \mathbf{\underline{M}} \mathbf{u}
    \label{equ:numerical-eigenmodes}
\end{equation}
involving the stiffness matrix $\mathbf{\underline{K}}$ and mass matrix $\mathbf{\underline{M}}$.
This can for instance be accomplished with the \texttt{eigsh} sparse eigenvalue
solver included in the \texttt{scipy} Python library. However, it is first necessary
to remove all the columns and rows from $\mathbf{\underline{K}}$ and $\mathbf{\underline{M}}$
that correspond to points on the perfectly conducting boundary, since they are
all zero after having assembled the matrices. This was demonstrated in Section
\ref{subsec:fem-demo}. In Table \ref{tab:rectangular_cavity_comparison}, I compare
the two approaches (\texttt{eigsh} and \acrshort{gMRI}) in their mean absolute deviation
$\Delta$ of the six resonant frequencies inside the interval $\omega = [3, 5]$ 
from their corresponding analytical resonances. Furthermore, the time each method
requires to produce a result given the assembled matrices $\mathbf{\underline{K}}$
and $\mathbf{\underline{M}}$ is measured over multiple runs on a 7th generation
Intel 8750H CPU at 2.20 GHz using the \texttt{timeit} library. This is done
for four logarithmically spaced refinements of the mesh with a resulting number
of \acrfull{DOF}.

\begin{table}[ht]
    \caption{In the same context as on the previous pages, two approaches to
    finding resonant frequencies: The sparse hermitian eigenvalue solver
    \texttt{eigsh} from the \texttt{scipy} library and the procedure using
    \acrshort{gMRI} that was introduced in Section \ref{subsec:roots}. For
    various \acrshort{DOF}s, the mean absolute deviation $\Delta$ from the analytical
    resonant frequencies and the time spent in computation $t$ are shown.}
    \label{tab:rectangular_cavity_comparison}
    \input{tables/rectangular_cavity_comparison.tex}
\end{table}

Hereafter I would like to discuss two major benefits the \acrshort{gMRI} method
for finding resonant modes holds over the \texttt{eigsh} approach.

Fistly, \texttt{eigsh} requires us to specify the exact number of eigenvalues that
should be approximated. Unless it is a priori known how many resonant modes are
expected to fall within an interval of interest, there is no guarantee of having
found all. The \acrshort{gMRI} way will reliably find all resonant modes within
and even in a close neighborhood of the interval of interest.

% Problems with non-resonant solutions suppressed by the boundary integral
Secondly, while solving the generalized eigenvalue problem, some resonant modes
are identified that, depending on the boundary condition at the inlet, are 
suppressed and do not emerge when solving the actual problem. Moreover, even
the analytical resonant frequencies suffer from the exact same effect. The reason
for this caveat is the following:

Take $\{ \mathbf{u}_j, \omega_j^2 \}_j$ to be resonant modes, i.e. solutions to 
the eigenvalue problem (\ref{equ:numerical-eigenmodes}), such that
\begin{equation}
    \mathbf{\underline{K}} \mathbf{u}_j = \omega_j^2 \mathbf{\underline{M}} \mathbf{u}_j
    \label{equ:eigen-solution}
\end{equation}
Adding a source term $\mathbf{f}$, the new system is described by
\begin{equation}
    \mathbf{\underline{K}} \mathbf{u} - \omega^2 \mathbf{\underline{M}} \mathbf{u} = \mathbf{f}
\end{equation}
If a solution $\mathbf{u}$ can be expressed in terms of the basis $\{ \mathbf{u}_j \}_j$,
meaning $\mathbf{u} = \sum_j \alpha_j \mathbf{u}_j$ for some $\alpha_j$, then
\begin{equation} 
    \sum_j \alpha_j (\mathbf{\underline{K}} \mathbf{u}_j - \omega^2 \mathbf{\underline{M}} \mathbf{u}_j) = \mathbf{f}
\end{equation}
Using (\ref{equ:eigen-solution}) yields
\begin{equation}
    \sum_j \alpha_j (\omega_j^2 - \omega^2) \mathbf{\underline{M}} \mathbf{u}_j = \mathbf{f}
\end{equation}
from which we can then multiply both sides with $\mathbf{u}_i^H$ to obtain
% WHY SHOULD THIS BE A BASIS (DOES IT SPAN?), AND WHY M-ORTHONORMAL
\begin{equation}
    \alpha_i = \frac{\mathbf{u}_i^H \mathbf{f}}{\omega_i^2 - \omega^2} \label{equ:suppression}
\end{equation}
using $\mathbf{u}_i^H \mathbf{\underline{M}} \mathbf{u}_j = \delta_{ij}$
since the eigenvectors stemming from a hermitian eigenvalue problem can be made 
$\mathbf{\underline{M}}$-orthonormal.

Inspecting (\ref{equ:suppression}), we see that if $\mathbf{u}_i^H \mathbf{f} = 0$,
then the resonant mode at $\omega = \omega_i$ is suppressed. Because neither the
generalized eigenvalue problem nor the analytical considerations
are informed about the nature of the source term $\mathbf{f}$, this is not accounted for.
Specifying as the initial iteration vector for the \texttt{eigsh} eigenvalue solver
the source term $\mathbf{f}$ to avoid finding eigensolutions that are orthogonal
to it did not prove to be effective.

\begin{figure}[ht]
    \centering
    \input{plots/rectangular_cavity_suppression.pgf}
    \caption{For still the same problem but this time in a slightly higher
    frequency range $\omega = [6, 7]$, resonant frequencies determined using the
    three discussed approaches are shown (bottom). Only two resonant
    frequencies visibly emerge from the $||.||_M$-norm spectrum determined by
    solving the problem with the \acrshort{FEM} (top). Suppressed resonant
    frequencies appear (or much rather do not appear) whenever the corresponding
    eigensolution $u(\omega_{n, m})$ is orthogonal to the source term $f$ (middle).}
    \label{fig:rectangular-cavity-suppression}
\end{figure}

\subsubsection{Approximating solutions along a trace}
\label{subsubsec:traces}

I now restrict my view to solutions $u|_{\Gamma}$ along a trace $\Gamma$. Setting
\begin{equation}
    ||u||_{M(\Gamma)}^2 = \mathbf{u}|_{\Gamma}^H \mathbf{\underline{M}}(\Gamma) \mathbf{u}|_{\Gamma}
        \approx \int_{\Gamma} u^2
\end{equation}
Running \acrshort{gMRI} (Algorithm \ref{alg:gMRI}) on the restriction $u|_{\Gamma}$
instead of the full solution $u$ is a straight forward generalization of the
algorithm. Nevertheless, when taking as $\Gamma = \Gamma_N$ the inlet of the
rectangular resonant cavity, no convergence in the relative error norm restricted
to this trace appears to happen with \acrshort{gMRI} (see Figure \ref{fig:rectangular-cavity-trace-errornorm}),
and the spectral gap (\ref{equ:spectral-gap}) becomes gigantic.
This is due to the fact that the traces of the solutions at the boundary $\Gamma_N$
are heavily linearly dependent.
%, and while trying to computing the \acrshort{SVD}, (MUST IMPROVE THIS EXPLANATION)
%a lot of information is compressed into one component

\begin{figure}[ht]
    \centering
    \input{plots/rectangular_cavity_trace_errorprogression.pgf}
    \caption{The non-convergent behavior of the approximate relative error norm
    during every second iteration of \acrshort{gMRI} of the solution
    restricted to the inlet $\Gamma_N$. Here, $\tilde{u}|_{\Gamma_N}^{(S)}$ stands 
    for the rational surrogate for the solution on the trace built using $S$
    support points.}
    \label{fig:rectangular-cavity-trace-errornorm}
\end{figure}

The symmetry may be broken by introducing a small \enquote{cubby} along the side
of the cavity (see Figure \ref{fig:rectangular-cavity-cubby}). 

\begin{figure}[h]
    \centering
    \input{figures/rectangular_cavity_cubby.tex}
    \caption{A tiny cubby is introduced alongside one of the edges in order to
    break the linear dependence of solutions restricted to a trace. It extends
    along a quarter of the length of the cavity but extends outwards only by
    1/100-th of the height of the cavity.}
    \label{fig:rectangular-cavity-cubby}
\end{figure}

Desipte the only tiny perturbation in the geometry of the cavity, the improved
convergence behavior may immediately be seen in Figure \ref{fig:rectangular-cubby-trace-errornorm}.

\begin{figure}[ht]
    \centering
    \input{plots/rectangular_cubby_trace_errorprogression.pgf}
    \caption{Breaking the symmetry (i.e. the linear dependence of the solutions
    on a trace) with a tiny cubby (see Figure \ref{fig:rectangular-cavity-cubby})
    proves to be a quite effective remedy for the stability in building the
    rational surrogate with \acrshort{gMRI}. For every second iteration of the 
    algorithm, an estimate for the relative error of the surrogate $u_{\Gamma_N}^{(S)}$
    built with $S$ support points (shown at the bottom) is plotted. Compared to
    Figure \ref{fig:rectangular-cavity-trace-errornorm}, the error goes down much
    more uniformly.}
    \label{fig:rectangular-cubby-trace-errornorm}
\end{figure}

\clearpage
\subsection{Imperfectly conducting boundaries}
\label{subsec:examples-impedance}

A slight modification of the problem (derived in Section \ref{subsubsec:impedance})
brings us to the example of an imperfectly conducting boundary. At the edge 
opposite of the inlet (i.e. $x=L_x$), the impedance is set to $\lambda=1$.

A solution to the system is plotted in Figure \ref{fig:imperfect-conductor-solution}
and the $||.||_M$-norm for both the \acrshort{FEM} and \acrshort{gMRI}
are plotted in Figure \ref{fig:imperfect-conductor-norms}.

\begin{figure}[ht]
    \centering
    \includegraphics{plots/imperfect_conductor_solution.pdf}
    \caption{The solution $u_z(x, y)$ obtained with the \acrshort{FEM} at the
    frequency $\omega = 3.5$. Unlike in Figures \ref{fig:rectangular-cavity-mode1}
    and \ref{fig:rectangular-cavity-mode5}, the solution does no longer have to
    vanish at the imperfect boundary on the right-hand edge.}
    \label{fig:imperfect-conductor-solution}
\end{figure}

\begin{figure}[ht]
    \centering
    \input{plots/imperfect_conductor_norms.pgf}
    \caption{The $||.||_M$-norm of the \acrshort{FEM} solution $\mathbf{u}(\omega)$ (top) and
    its surrogate $\mathbf{\tilde{u}}(\omega)$ (middle) for the rectangular cavity with
    an imperfectly conducting edge is shown. The locations of the greedy support
    points are indicated (bottom).}
    \label{fig:imperfect-conductor-norms}
\end{figure}

To find resonant frequencies for this system numerically, the nonlinear eigenproblem
\begin{equation}
    (\mathbf{\underline{K}} - i \omega \mathbf{\underline{I}} - \omega^2 \mathbf{\underline{M}}) \mathbf{u} = \mathbf{0} \label{equ:nonlinear-eigenproblem}
\end{equation}
with $\mathbf{I}$ being the matrix representation of the form
\begin{equation}
    \int_{\partial \Omega} \lambda u_z v_z 
\end{equation}
Unfortunately, solving this eigenvalue problem is not as straight forward as the
one that was encountered in the previous example. Likely the simplest approach
to solving (\ref{equ:nonlinear-eigenproblem}) is to linearize the system by
defining $\mathbf{v} = \omega \mathbf{u}$, such that we can convert it to a
system twice the size that reads
\begin{equation}
    \begin{bmatrix}
         & \boldsymbol{\underline{1}} \\
        \mathbf{\underline{K}} & -i \mathbf{\underline{I}}
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{u} \\
        \mathbf{v}
    \end{bmatrix}
    =
    \omega
    \begin{bmatrix}
        \boldsymbol{\underline{1}} & \\
         & \boldsymbol{\underline{M}}
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{u} \\
        \mathbf{v}
    \end{bmatrix}
\end{equation}
Usually, however, the two matrices involved in the eigenproblem are no longer
going to be hermitian. Combined with the fact that the problem is now twice
the size of the original one, solving the system with the sparse eigenvalue
solver \texttt{eigs} included in the \texttt{scipy} library will cost more
computational resources than \acrshort{gMRI} does (see Table \ref{tab:imperfect-conductor-comparison}
for the comparison of the time spent in computation between the two methods).
% Why as diagonal as possible?

\begin{table}[ht]
    \caption{Comparison of the computation times for identifying the resonant
    frequencies with a real part in the interval $\omega=[3, 5]$ between \texttt{eigs} and
    \acrshort{gMRI} with a tolerance of $\tau = 10^{-2}$. To get a full
    comparison to the equivalent computations in Table \ref{tab:rectangular_cavity_comparison}
    an attempt was made to use \texttt{eigs} for solving the problem with 
    745513 \acrshort{DOF}s, but proved to be unsuccessful due to a memory overflow.}
    \label{tab:imperfect-conductor-comparison}
    \input{tables/imperfect_conductor_comparison.tex}
\end{table}

The effect of the impedance $\lambda$ on the position of the (complex) resonant
frequencies is visualized in Figure \ref{fig:imperfect-conductor-eigfreqs}.
For $\lambda \to 0$ we recover a Neumann boundary condition, while for 
$\lambda \to \infty$, a Dirichlet-type boundary is produced.
% REMINDME! ^^^ a bit vague
% argmin |Q| only valid in undamped regime
\begin{figure}[ht]
    \centering
    \input{plots/imperfect_conductor_eigfreqs.pgf}
    \caption{Resonant frequencies of a rectangular cavity with an imperfect boundary
    with impedances $\lambda \in \{0.1, 1, 10\}$. Spurious resonant frequency far
    away from the relevant interval are not of interest for this problem and hence
    cropped off.}
    \label{fig:imperfect-conductor-eigfreqs}
\end{figure}

\clearpage
\subsection{Dual mode circular waveguide filter}
\label{subsec:examples-dmcwf}

% Describe geometry and physical meaning
The \acrfull{DMCWF} depicted in Figure \ref{fig:DMCWF} is studied. It is a
highly symmetric three-dimensional waveguide that consists of two opposing
ports connected by a cylinder that is split in two by a cross iris. 
Breaking this symmetry are merely four screws: The two horizontal tuning
screws as well as the two coupling screws. A brief theoretical treatment is given
in Section \ref{subsubsec:waveguide}.

\begin{figure}[h]
    \centering
    \input{figures/DMCWF.tex}
    \caption{The surface-mesh of the modelled dual-mode circular waveguide filter
    (left). An effort was made to keep the dimensions as similar to the ones
    given in \cite{DMCWF-Dimensions}, but a full correspondence cannot be guaranteed
    due to yours truly being unable to resolve certain ambiguities that were encountered.
    The model adheres to the following dimensions:
    $W_C=43.87$ mm, $D_C=28.0$ mm, $L_B=43.87$ mm, $W_B=19.05$ mm, $H_B=9.525$ mm,
    $L_B=20.0$ mm, $W_S=10.05$ mm, $H_S=3.0$ mm, $W_A=2.0$ mm, $H_A=3.375$ mm,
    $L_A=2.825$ mm; The thickness of all irises is $2.0$ mm; The screws
    are placed exactly half way up the two resonant cylinders,
    with the horizontal tuning screws reaching a depth of $3.82$ mm into the cavity
    and coupling screws at angles $\pm 45^{\circ}$ with a depth of $3.57$ mm.
    Observe that the \acrshort{DMCWF} is point symmetric with respect to the center 
    of the cross iris.}
    \label{fig:DMCWF}
\end{figure}

% Modeling process cite rubia
I created the model in the computer-aided design modeler software application
FreeCAD\footnote{\url{https://www.freecadweb.org/}}. The mesh was defined using 
the 3D finite element mesh generator Gmsh\footnote{\url{https://gmsh.info/}} and 
is available for download on the git repository 
of this project \cite{git}. In Gmsh, a element size factor of 0.2 and 5 smoothing steps
are used for the Delaunay 3D meshing algorithm. Additionally, 
the mesh was refined around critical components such as the screws and irises
using transfinite curves (the sharp-eyed reader may observe these refinements
in the surface mesh visualized in Figure \ref{fig:DMCWF}). A total of
185726 \acrshort{DOF}s are accounted for. The conversion of the
mesh to the FEniCS supported .xml format was performed with the mesh format converter
meshio\footnote{\url{https://github.com/nschloe/meshio}}. 

% Scattering coefficient
In the following, I would like to demonstrate the capability of the 
\acrshort{gMRI} algorithm to approximate scattering coefficients for the \acrshort{DMCWF}.
The definition of the scattering matrix is a adaptation from \cite{shortMRI} to
\begin{equation}
    \mathbf{\underline{S}}(\omega) = \mathbf{\underline{1}}
    - 2\left( \mathbf{\underline{1}} + i \frac{\omega}{2\pi} \sqrt{\frac{\mu}{\epsilon}}
    \sqrt{\frac{1 - (\omega_c / \omega_0)^2}{1 - (\omega_c / \omega)^2}} 
    \mathbf{\underline{F}}^H \mathbf{\underline{U}}(\omega) \right)^{-1}
\end{equation}
where $\mathbf{\underline{F}} = [\mathbf{f}_1, \mathbf{f}_2]$ and
$\mathbf{\underline{U}} = [\mathbf{u}_1, \mathbf{u}_2]$ with $\mathbf{f}_1$ the source term
resulting when the \acrshort{DMCWF} is forced from one side, producing the
solution $\mathbf{u}_1$, and the $\mathbf{f}_2$ when forcing from the other side to
produce $\mathbf{u}_2$. $\omega_c = 4.122 \times 10^{10}$ and $\omega_0 = 6.283 \times 10^{10}$
were assumed. The scattering coefficients $S_{ij}$ are then precisely the
entries of the scattering matrix
\begin{equation}
    \mathbf{\underline{S}}(\omega) =
    \begin{bmatrix}
            S_{11}(\omega) & S_{12}(\omega) \\
            S_{21}(\omega) & S_{22}(\omega)
    \end{bmatrix}\label{equ:scattering-coefficients}
\end{equation}

For the simulation, $\epsilon = 4 \pi \times 10^{-7}$ and 
$\mu = 8.854187 \times 10^{-12}$ were assumed. The one-sided forcing
was performed with $\left.\mathbf{g}\right|_{\Gamma_i} = - \mathbf{e}_z$ from the
left-hand inlet, and $\left.\mathbf{g}\right|_{\Gamma_i} = \mathbf{e}_z$ from the
right-hand inlet. The scattering coefficients $S_{11}(\omega)$ and $S_{12}(\omega)$
once computed by using the solutions at 150 uniformly spaced sample frequencies
directly obtained with the \acrshort{FEM},
and once from the rational surrogate computed with \acrshort{gMRI} at a tolerance
of $\tau = 10^{-2}$. Both are shown (but only one is seen) in Figure
\ref{fig:circular-waveguide-scattering}. At somewhat more than four minutes,
the \acrshort{gMRI} was able to deliver the approximated scattering coefficients
roughly 25 times faster than the \acrshort{FEM}. Compared to \cite{DMCWF-FrequencySweep},
the passband is shifted to a slightly lower frequency.

\begin{figure}[ht]
    \centering
    \input{plots/circular_waveguide_scattering.pgf}
    \caption{The scattering coefficients $S_11(\omega)$ and $S_22(\omega)$
    defined in (\ref{equ:scattering-coefficients}) computed as a reference
    from solving the system at discrete sample points and the
    \acrshort{FEM}, as well as the ones obtained by using \acrshort{gMRI}.}
    \label{fig:circular-waveguide-scattering}
\end{figure}

The progression of the
absolute error with the number of support points used to build the surrogate
can be seen in Figure \ref{fig:circular-waveguide-error}.

\begin{figure}[ht]
    \centering
    \input{plots/circular_waveguide_error.pgf}
    \caption{Progression of the absolute error between the reference scattering
    coefficients ($S_{11, \textrm{FEM}}$ and $S_{12, \textrm{FEM}}$) obtained by solving the problem with \acrshort{FEM} and the 
    ones obtained by using \acrshort{gMRI} ($S_{11, \textrm{gMRI}}$ and $S_{12, \textrm{gMRI}}$).}
    \label{fig:circular-waveguide-error}
\end{figure}

\clearpage
\newpage
\section{Conclusion and outlook}
\label{sec:conclusion}

In the above report I have studied the suitability of the \acrfull{MRI} method and
particularly the \acrfull{gMRI} algorithm for the time-harmonic Maxwell's equations.
In general, the \acrshort{gMRI} algorithm paired with the \acrfull{FEM} 
offer an efficient, reliable and flexible way of producing an approximation 
of the frequency dependence of the vector potential $\mathbf{u}$ in problems
of the form (\ref{equ:maxwell-timeharmonic}).

Finding resonant frequencies of a simple system with the help of \acrshort{gMRI} was found to 
be comparable to conventional approaches when considering the accuracy and
time spent in computation (cf. Section \ref{subsec:examples-rectangularcavity}
and particularly Table \ref{tab:rectangular_cavity_comparison}). In terms of
ease of use, \acrshort{gMRI} proved to exhibit the key property of not incorrectly
identifying resonant frequencies that are suppressed in the case of a highly
symmetric model (Figure \ref{fig:rectangular-cavity-suppression}). Furthermore,
with \acrshort{gMRI} no a priori knowledge of the number of resonant frequencies
is required, which is not the case with the conventional approach the method was
compared to.

Furthermore, specifically for larger and more complex systems, e.g.
the nonlinear eigenproblem solved in Section \ref{subsec:examples-impedance}
or the treatment of the \acrfull{DMCWF} in Section \ref{subsec:examples-dmcwf},
excelled in its performance mainly due to its scalability and time efficiency.

A problem with the presence of linearly combinable resonant modes, mainly present
when restricting the view to only a trace of the full solution, was identified
in Section \ref{subsubsec:traces} and remedies were suggested and tested to be
effective in resolving this issue.

Further work would have to be put into the study of the \acrshort{DMCWF}, after
a proper verification of both the dimensions and the meshing with a reference
model has been conducted. It would also be interesting to study \acrshort{gMRI}
for a wider class of time-harmonic Maxwell problems, for instance with a non-trivial
current density $\mathbf{j}$ or systems with spatially dependent $\epsilon$ and
$\mu$. Using the implementations I have published in \cite{git}, these extensions
are made completely straightforward to add into the code.

\newpage
\bibliography{biblio.bib}

\newpage
\section*{Appendix}
\label{sec:appendix}

This section contains some derivations that did not end up making it into the
report, but were too much fun not to include them anyway. Most of them make
use of the Levi-Civita tensor. This completely antisymmetric tensor
$\varepsilon_{ijk}$ is fully characterized by the following defining properties:
\begin{align}
    \begin{cases}
        \varepsilon_{123} = 1 & \text{gauge}\\
        \varepsilon_{ijk} = 0~~\text{if}~~|\{i, j, k\}| < 3 & \text{cardinality} \\
        \varepsilon_{ijk} = \varepsilon_{jki} & \text{cyclic permutation}\\
        \varepsilon_{ijk} = - \varepsilon_{ikj} & \text{non-cyclic permutation}
        \label{equ:levi-civita-properties}
    \end{cases}
\end{align}
It may be employed to rewrite the
components of the curl of a vector-function $\mathbf{a}$ as the sum
\begin{equation}
    (\nabla \times \mathbf{a})_k = \sum_i \sum_j \varepsilon_{ijk} \partial_i a_j \label{equ:levi-civita}
\end{equation}
where $\partial_i$ denotes the partial derivative with respect to the $i$-th coordinate
direction.

\subsection*{Detailed derivation for the weak formulation of the time-harmonic potential equation}
\label{subsec:derivation}

The goal is to rewrite the curl-integral on the left-hand side of 
(\ref{equ:maxwell-weak-initial}):
\begin{equation}
    \int_{\Omega} (\nabla \times (\mu^{-1} \nabla \times \mathbf{u})) \cdot \mathbf{v} \label{equ:maxwell-weak-initial-LHS}
\end{equation}
In order to simplify the curls and apply the Gauss theorem, I first show
the following vector calculus identity:
\begin{fancybox}{Curl product rule}
    \begin{equation}
        (\nabla \times \mathbf{a}) \cdot \mathbf{b} = \nabla \cdot (\mathbf{a} \times \mathbf{b}) + \mathbf{a} \cdot (\nabla \times \mathbf{b}) \label{equ:vector-calculus}
    \end{equation}
\end{fancybox}
where $\mathbf{a}$, $\mathbf{b}$ are vector-valued functions. Rewriting the 
left-hand side of this equation by using the Levi-Civita tensor (\ref{equ:levi-civita})
yields
\begin{align}
    (\nabla \times \mathbf{a}) \cdot \mathbf{b} &= \sum_k (\nabla \times \mathbf{a})_k b_k \notag \\ 
    &= \sum_k (\sum_i \sum_j \varepsilon_{ijk} \partial_i a_j) b_k \notag \\ 
    &= \sum_k \sum_i \sum_j \partial_i (\varepsilon_{ijk} a_j b_k) - \sum_k \sum_i \sum_j a_j (\varepsilon_{ijk} \partial_i b_k) \notag \\ 
    &= \sum_k \sum_i \sum_j \partial_i (\varepsilon_{jki} a_j b_k) - \sum_k \sum_i \sum_j a_j ((-\varepsilon_{ikj}) \partial_i b_k) \notag \\ 
    &= \sum_i \partial_i (\mathbf{a} \times \mathbf{b})_i + \sum_j u_j (\nabla \times \mathbf{b})_j \notag \\ 
    &= \nabla \cdot (\mathbf{a} \times \mathbf{b}) + \mathbf{a} \cdot (\nabla \times \mathbf{b}) \label{equ:curlidentity} 
\end{align}
by expressing the scalar product as a component-sum, using the product rule and
applying the symmetry and anti-symmetry properties of the Levi-Civita tensor.
Now the identity (\ref{equ:vector-calculus}) to (\ref{equ:maxwell-weak-initial-LHS})
together with Gauss' theorem gives
\begin{align}
    \int_{\Omega} (\nabla \times ({\mu^{-1} \nabla \times \mathbf{u}})) \cdot \mathbf{v} &=
    \int_{\Omega} \nabla \cdot (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{v})
    + \int_{\Omega} ({\mu^{-1} \nabla \times \mathbf{u}}) \cdot (\nabla \times \mathbf{v}) \notag \\
    &= \int_{\partial \Omega} (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{v}) \cdot \mathbf{n}
    + \int_{\Omega} ({\mu^{-1} \nabla \times \mathbf{u}}) \cdot (\nabla \times \mathbf{v}) \notag \\
\end{align}

For later convenience, the boundary integral can further be simplified using the
\begin{fancybox}{Commutative behavior of the scalar triple product}
    \begin{equation}
        (\mathbf{a} \times \mathbf{b}) \cdot \mathbf{c} = - (\mathbf{a} \times \mathbf{c}) \cdot \mathbf{b} \label{equ:vector-algebra}
    \end{equation}
\end{fancybox}
This identity follows immediately from a small manipulation with the Levi-Civita
tensor:
\begin{align}
    (\mathbf{a} \times \mathbf{b}) \cdot \mathbf{c} &= \sum_k (\sum_i \sum_j \varepsilon_{ijk} a_i b_j) c_k \notag \\
     &= \sum_j (\sum_i \sum_k (-\varepsilon_{ikj}) a_i c_k) b_j \notag \\ 
     &= - (\mathbf{a} \times \mathbf{c}) \cdot \mathbf{b} 
\end{align}
The boundary integral becomes 
\begin{equation}
    \int_{\partial \Omega} (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{v}) \cdot \mathbf{n}
    = - \int_{\partial \Omega} (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{n}) \cdot \mathbf{v}
\end{equation}

This concludes the short derivation, because now (\ref{equ:maxwell-weak-initial-LHS})
may be rewritten as
\begin{equation}
    - \int_{\partial \Omega} (({\mu^{-1} \nabla \times \mathbf{u}}) \times \mathbf{v}) \cdot \mathbf{n}
    + \int_{\Omega} ({\mu^{-1} \nabla \times \mathbf{u}}) \cdot (\nabla \times \mathbf{v})
\end{equation}

\subsection*{Invariance of repeated cross products}
\label{subsec:invariance}

I would like to demonstrate the
\begin{fancybox}{Invariance of repeated cross products}
    If $\mathbf{n} \perp \mathbf{u}$ and $||\mathbf{n}|| = 1$, then
    \begin{equation}
        (\mathbf{n} \times \mathbf{u}) \times \mathbf{n} = \mathbf{u} \label{equ:double-cross-normal}
    \end{equation}
\end{fancybox}

I again resort to the old faithful Levi-Civita tensor which satisfies the
identity
\begin{equation}
    \sum_i \varepsilon_{jki} \varepsilon_{lmi} = \delta_{jl} \delta_{km} - \delta_{jm} \delta_{kl}
\end{equation}
Furthermore, I make use of the invariance of the tensor under cyclic permutation
of the indices (according to Equation (\ref{equ:levi-civita-properties})) to obtain
\begin{align}
    [(\mathbf{n} \times \mathbf{u}) \times \mathbf{n}]_k
    &= \sum_i \sum_j \varepsilon_{ijk} (\mathbf{n} \times \mathbf{u})_i n_j \notag \\ 
    &= \sum_i \sum_j \varepsilon_{ijk} \sum_l \sum_m \varepsilon_{lmi} n_l u_m n_j \notag \\ 
    &= \sum_i \sum_j \sum_l \sum_m \varepsilon_{jki} \varepsilon_{lmi} n_l u_m n_j \notag \\ 
    &= \sum_j \sum_l \sum_m (\delta_{jl} \delta_{km} - \delta_{jm} \delta_{kl}) n_l u_m n_j \notag \\
    &= \sum_j n_j u_k n_j - \sum_j n_k u_j n_j \notag \\
    &= ||\mathbf{n}||^2 u_k - (\mathbf{u} \cdot \mathbf{n}) n_k \notag \\ 
    &= u_k
\end{align}
which concludes the component-wise proof.
\end{document}